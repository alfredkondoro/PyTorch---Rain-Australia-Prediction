{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7173717",
   "metadata": {
    "_cell_guid": "56b20ae5-ce7c-4b9f-8022-9182612d0b8d",
    "_uuid": "1a7255c1-c421-48b6-8719-77212d3c83e0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:45.924670Z",
     "iopub.status.busy": "2024-04-02T04:55:45.923882Z",
     "iopub.status.idle": "2024-04-02T04:55:55.800176Z",
     "shell.execute_reply": "2024-04-02T04:55:55.798951Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.888937,
     "end_time": "2024-04-02T04:55:55.803274",
     "exception": false,
     "start_time": "2024-04-02T04:55:45.914337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c209584",
   "metadata": {
    "_cell_guid": "e21df019-2944-4cff-a0e3-83714a947060",
    "_uuid": "1318cfa4-4c9d-4966-b398-0914ffcef75e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:55.821080Z",
     "iopub.status.busy": "2024-04-02T04:55:55.820013Z",
     "iopub.status.idle": "2024-04-02T04:55:55.826717Z",
     "shell.execute_reply": "2024-04-02T04:55:55.825812Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017753,
     "end_time": "2024-04-02T04:55:55.828769",
     "exception": false,
     "start_time": "2024-04-02T04:55:55.811016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "frac_train = 0.8\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "learning_rates = [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "optimizers = {\n",
    "    'SGD': torch.optim.SGD,\n",
    "    'RMSprop': torch.optim.RMSprop,\n",
    "    'Adam': torch.optim.Adam,\n",
    "    #'LBFGS' : torch.optim.LBFGS,\n",
    "}\n",
    "epoch_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf12ae38",
   "metadata": {
    "_cell_guid": "d8af6558-0906-4f26-9623-21e4644ac8a5",
    "_uuid": "0ede7cbe-d5ed-432a-99af-1ad03b230949",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:55.845199Z",
     "iopub.status.busy": "2024-04-02T04:55:55.844768Z",
     "iopub.status.idle": "2024-04-02T04:55:56.518029Z",
     "shell.execute_reply": "2024-04-02T04:55:56.516799Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.684455,
     "end_time": "2024-04-02T04:55:56.520612",
     "exception": false,
     "start_time": "2024-04-02T04:55:55.836157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "dataset = pd.read_csv(\"/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc61145",
   "metadata": {
    "_cell_guid": "4c13a74c-9a80-44fe-9727-f569210442e8",
    "_uuid": "3d2e0e00-32f1-4986-94bd-3f7e3eef1c36",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.537458Z",
     "iopub.status.busy": "2024-04-02T04:55:56.537084Z",
     "iopub.status.idle": "2024-04-02T04:55:56.573010Z",
     "shell.execute_reply": "2024-04-02T04:55:56.571931Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.047831,
     "end_time": "2024-04-02T04:55:56.575568",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.527737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd7b10f",
   "metadata": {
    "_cell_guid": "fa707e6e-badb-4f34-ac91-fc5062dfc4b5",
    "_uuid": "8e3dd5b5-fa69-474f-8413-42a1494a4b0b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.593090Z",
     "iopub.status.busy": "2024-04-02T04:55:56.592265Z",
     "iopub.status.idle": "2024-04-02T04:55:56.655864Z",
     "shell.execute_reply": "2024-04-02T04:55:56.654988Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.075219,
     "end_time": "2024-04-02T04:55:56.658577",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.583358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_columns = dataset.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "for column in numeric_columns:\n",
    "    median_value = int(dataset[column].median())\n",
    "    dataset[column].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1574873b",
   "metadata": {
    "_cell_guid": "bc7499b3-fbcd-4eae-a6d9-2c19373d8906",
    "_uuid": "d9aa926c-9fc3-45ab-b23c-de986e138c90",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.675279Z",
     "iopub.status.busy": "2024-04-02T04:55:56.674847Z",
     "iopub.status.idle": "2024-04-02T04:55:56.743641Z",
     "shell.execute_reply": "2024-04-02T04:55:56.742520Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.080139,
     "end_time": "2024-04-02T04:55:56.746050",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.665911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RainToday\n",
       "No     110319\n",
       "Yes     31880\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_encode = ['RainToday', 'RainTomorrow']\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    mode_value = dataset[column].mode()\n",
    "    dataset[column].fillna(mode_value, inplace=True)\n",
    "    \n",
    "dataset['RainToday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3ea68e",
   "metadata": {
    "_cell_guid": "a9ed2836-e210-4911-a9bf-cba45f5c7a4e",
    "_uuid": "40f84ac0-6da1-46f4-99e3-bc35923bef32",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.763066Z",
     "iopub.status.busy": "2024-04-02T04:55:56.762671Z",
     "iopub.status.idle": "2024-04-02T04:55:56.835074Z",
     "shell.execute_reply": "2024-04-02T04:55:56.833690Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.08425,
     "end_time": "2024-04-02T04:55:56.837657",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.753407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    dataset[column] = label_encoder.fit_transform(dataset[column])\n",
    "    \n",
    "#from deduction, all the null values remained null, hence produced encoded value of 2\n",
    "dataset['RainToday'].replace(2, 0, inplace=True)\n",
    "dataset['RainTomorrow'].replace(2, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1a18c0",
   "metadata": {
    "_cell_guid": "f459e4e9-8f26-4180-a42a-8b1fbd6c67fe",
    "_uuid": "cdca04a1-ae4b-4ee7-a31f-727b0a7a09dd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.855500Z",
     "iopub.status.busy": "2024-04-02T04:55:56.855086Z",
     "iopub.status.idle": "2024-04-02T04:55:56.908463Z",
     "shell.execute_reply": "2024-04-02T04:55:56.907270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.065956,
     "end_time": "2024-04-02T04:55:56.911285",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.845329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset['Date'] = pd.to_datetime(dataset['Date'], errors='coerce')\n",
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['Day'] = dataset['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469ce3a6",
   "metadata": {
    "_cell_guid": "6da90727-a3c5-4d26-b6dc-9612e6e1d6aa",
    "_uuid": "574786e7-f6d6-4c4a-80a3-d96626e95d68",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.928504Z",
     "iopub.status.busy": "2024-04-02T04:55:56.928121Z",
     "iopub.status.idle": "2024-04-02T04:55:56.947884Z",
     "shell.execute_reply": "2024-04-02T04:55:56.946766Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030865,
     "end_time": "2024-04-02T04:55:56.950299",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.919434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "object_columns = dataset.select_dtypes(include=['object']).columns\n",
    "dataset = dataset.drop(object_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6199c87",
   "metadata": {
    "_cell_guid": "167ca53a-7209-440b-bd97-df4960e4c215",
    "_uuid": "ba93a858-55eb-4098-a309-d18fad6a659f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:56.967302Z",
     "iopub.status.busy": "2024-04-02T04:55:56.966904Z",
     "iopub.status.idle": "2024-04-02T04:55:56.996137Z",
     "shell.execute_reply": "2024-04-02T04:55:56.995014Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.041149,
     "end_time": "2024-04-02T04:55:56.998871",
     "exception": false,
     "start_time": "2024-04-02T04:55:56.957722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = dataset.select_dtypes(include=['number'])\n",
    "X = temp.drop(columns=['RainTomorrow'])  # Features\n",
    "y = dataset['RainTomorrow']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a29ea3",
   "metadata": {
    "_cell_guid": "9631d073-824d-49e5-8502-a1b979f6d8e8",
    "_uuid": "c9ccfcee-0757-4300-b8bc-a77ef8b629e6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.015371Z",
     "iopub.status.busy": "2024-04-02T04:55:57.014936Z",
     "iopub.status.idle": "2024-04-02T04:55:57.026064Z",
     "shell.execute_reply": "2024-04-02T04:55:57.025021Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.022049,
     "end_time": "2024-04-02T04:55:57.028320",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.006271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RainTomorrow\n",
       "0    113583\n",
       "1     31877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248bb443",
   "metadata": {
    "_cell_guid": "beeb6c84-1cdd-413a-b2f1-3d49dc4391be",
    "_uuid": "7df0fdf9-2980-45e6-994e-e6c7f3f9afd9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.045720Z",
     "iopub.status.busy": "2024-04-02T04:55:57.045316Z",
     "iopub.status.idle": "2024-04-02T04:55:57.114453Z",
     "shell.execute_reply": "2024-04-02T04:55:57.112989Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.081176,
     "end_time": "2024-04-02T04:55:57.117408",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.036232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.view(-1, 1)  # Reshape y to have shape [num_samples, 1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "custom_dataset = CustomDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e203e0",
   "metadata": {
    "_cell_guid": "e6c3189b-8a8e-4c75-911a-19ca14816d1e",
    "_uuid": "50ec66f7-fadb-4a1b-8084-4d96c0d0d69d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.135443Z",
     "iopub.status.busy": "2024-04-02T04:55:57.135041Z",
     "iopub.status.idle": "2024-04-02T04:55:57.169344Z",
     "shell.execute_reply": "2024-04-02T04:55:57.167741Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.046751,
     "end_time": "2024-04-02T04:55:57.172047",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.125296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(custom_dataset))  # 80% of the data for training\n",
    "test_size = len(custom_dataset) - train_size  # Remaining 20% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create DataLoader for test data\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c6efd7",
   "metadata": {
    "_cell_guid": "a20d771a-a212-4534-aea2-c541cf414abe",
    "_uuid": "87e9a805-93d0-4891-aa9d-ba810f7b0d47",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.190600Z",
     "iopub.status.busy": "2024-04-02T04:55:57.189625Z",
     "iopub.status.idle": "2024-04-02T04:55:57.224886Z",
     "shell.execute_reply": "2024-04-02T04:55:57.222820Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.047712,
     "end_time": "2024-04-02T04:55:57.227900",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.180188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 20])\n",
      "Shape of y: torch.Size([64, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2ae442",
   "metadata": {
    "_cell_guid": "163a4c18-235c-4cc5-8d42-9b015a5a4f32",
    "_uuid": "930331b7-3093-4841-87c0-de2748693c4a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.245953Z",
     "iopub.status.busy": "2024-04-02T04:55:57.245550Z",
     "iopub.status.idle": "2024-04-02T04:55:57.263332Z",
     "shell.execute_reply": "2024-04-02T04:55:57.262053Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029553,
     "end_time": "2024-04-02T04:55:57.265489",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.235936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "RainPredictionModel(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Sample layers of Neural Network Class\n",
    "# nn.Linear(28*28, 512),\n",
    "# nn.ReLU(),\n",
    "# nn.Linear(512, 512),\n",
    "# nn.ReLU(),\n",
    "# nn.Linear(512, 10)\n",
    "\n",
    "# Define model\n",
    "class RainPredictionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RainPredictionModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "input_size = 20\n",
    "model = RainPredictionModel(input_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc8c3120",
   "metadata": {
    "_cell_guid": "267751cf-32d7-40cc-a384-3d3167b2d59a",
    "_uuid": "29ae5473-38e9-4809-9c2d-6f0619373ddf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.283495Z",
     "iopub.status.busy": "2024-04-02T04:55:57.282364Z",
     "iopub.status.idle": "2024-04-02T04:55:57.288309Z",
     "shell.execute_reply": "2024-04-02T04:55:57.287175Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017158,
     "end_time": "2024-04-02T04:55:57.290561",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.273403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a26832c",
   "metadata": {
    "_cell_guid": "da290c6f-3c2a-42a1-98ba-173e95a56830",
    "_uuid": "664f6405-76f9-48d4-9f31-ef4507c78193",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.307380Z",
     "iopub.status.busy": "2024-04-02T04:55:57.306938Z",
     "iopub.status.idle": "2024-04-02T04:55:57.314374Z",
     "shell.execute_reply": "2024-04-02T04:55:57.313170Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018382,
     "end_time": "2024-04-02T04:55:57.316594",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.298212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e333917c",
   "metadata": {
    "_cell_guid": "06f56ecc-2d86-44ed-92e1-694ef7f8a536",
    "_uuid": "6dbc09a8-7f6c-474f-b945-00ac6162c507",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.333456Z",
     "iopub.status.busy": "2024-04-02T04:55:57.333085Z",
     "iopub.status.idle": "2024-04-02T04:55:57.340037Z",
     "shell.execute_reply": "2024-04-02T04:55:57.339017Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018172,
     "end_time": "2024-04-02T04:55:57.342342",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.324170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e975ab0",
   "metadata": {
    "_cell_guid": "e301f79f-f89f-4269-b75e-19a2526e0d2e",
    "_uuid": "0ea6f13e-ccc3-42f4-b146-6e4fd2adbea4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:55:57.359880Z",
     "iopub.status.busy": "2024-04-02T04:55:57.359497Z",
     "iopub.status.idle": "2024-04-02T04:56:56.163708Z",
     "shell.execute_reply": "2024-04-02T04:56:56.162422Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 58.816552,
     "end_time": "2024-04-02T04:56:56.166915",
     "exception": false,
     "start_time": "2024-04-02T04:55:57.350363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.868112  [   64/116368]\n",
      "loss: 3.075163  [ 6464/116368]\n",
      "loss: 0.677168  [12864/116368]\n",
      "loss: 0.371817  [19264/116368]\n",
      "loss: 0.879155  [25664/116368]\n",
      "loss: 0.652016  [32064/116368]\n",
      "loss: 0.416867  [38464/116368]\n",
      "loss: 0.553933  [44864/116368]\n",
      "loss: 0.578514  [51264/116368]\n",
      "loss: 0.439409  [57664/116368]\n",
      "loss: 0.496143  [64064/116368]\n",
      "loss: 0.536984  [70464/116368]\n",
      "loss: 0.525116  [76864/116368]\n",
      "loss: 0.489000  [83264/116368]\n",
      "loss: 0.543052  [89664/116368]\n",
      "loss: 0.444804  [96064/116368]\n",
      "loss: 0.394935  [102464/116368]\n",
      "loss: 0.453788  [108864/116368]\n",
      "loss: 0.651393  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.712750 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.736026  [   64/116368]\n",
      "loss: 0.398076  [ 6464/116368]\n",
      "loss: 0.445216  [12864/116368]\n",
      "loss: 0.523768  [19264/116368]\n",
      "loss: 0.449758  [25664/116368]\n",
      "loss: 0.359796  [32064/116368]\n",
      "loss: 0.350704  [38464/116368]\n",
      "loss: 0.504366  [44864/116368]\n",
      "loss: 0.451435  [51264/116368]\n",
      "loss: 0.482067  [57664/116368]\n",
      "loss: 0.412405  [64064/116368]\n",
      "loss: 0.506602  [70464/116368]\n",
      "loss: 0.358266  [76864/116368]\n",
      "loss: 0.494317  [83264/116368]\n",
      "loss: 0.492912  [89664/116368]\n",
      "loss: 0.487760  [96064/116368]\n",
      "loss: 0.480296  [102464/116368]\n",
      "loss: 0.482885  [108864/116368]\n",
      "loss: 0.396240  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.645682 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.669477  [   64/116368]\n",
      "loss: 0.475589  [ 6464/116368]\n",
      "loss: 0.539455  [12864/116368]\n",
      "loss: 0.470282  [19264/116368]\n",
      "loss: 0.578365  [25664/116368]\n",
      "loss: 0.489292  [32064/116368]\n",
      "loss: 0.423717  [38464/116368]\n",
      "loss: 0.445005  [44864/116368]\n",
      "loss: 0.278036  [51264/116368]\n",
      "loss: 0.457686  [57664/116368]\n",
      "loss: 0.490936  [64064/116368]\n",
      "loss: 0.564813  [70464/116368]\n",
      "loss: 0.427208  [76864/116368]\n",
      "loss: 0.432843  [83264/116368]\n",
      "loss: 0.406691  [89664/116368]\n",
      "loss: 0.438906  [96064/116368]\n",
      "loss: 0.396925  [102464/116368]\n",
      "loss: 0.350081  [108864/116368]\n",
      "loss: 0.328539  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.419271 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.404389  [   64/116368]\n",
      "loss: 0.640136  [ 6464/116368]\n",
      "loss: 0.382083  [12864/116368]\n",
      "loss: 0.467162  [19264/116368]\n",
      "loss: 0.366726  [25664/116368]\n",
      "loss: 0.383156  [32064/116368]\n",
      "loss: 0.432583  [38464/116368]\n",
      "loss: 0.423100  [44864/116368]\n",
      "loss: 0.388971  [51264/116368]\n",
      "loss: 0.377535  [57664/116368]\n",
      "loss: 0.533219  [64064/116368]\n",
      "loss: 0.407357  [70464/116368]\n",
      "loss: 0.278234  [76864/116368]\n",
      "loss: 0.382138  [83264/116368]\n",
      "loss: 0.345418  [89664/116368]\n",
      "loss: 0.467185  [96064/116368]\n",
      "loss: 0.306485  [102464/116368]\n",
      "loss: 0.339944  [108864/116368]\n",
      "loss: 0.493453  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.740757 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.971039  [   64/116368]\n",
      "loss: 0.534450  [ 6464/116368]\n",
      "loss: 0.376789  [12864/116368]\n",
      "loss: 0.510379  [19264/116368]\n",
      "loss: 0.533014  [25664/116368]\n",
      "loss: 0.341962  [32064/116368]\n",
      "loss: 0.462170  [38464/116368]\n",
      "loss: 0.425850  [44864/116368]\n",
      "loss: 0.427297  [51264/116368]\n",
      "loss: 0.373397  [57664/116368]\n",
      "loss: 0.496801  [64064/116368]\n",
      "loss: 0.479910  [70464/116368]\n",
      "loss: 0.429495  [76864/116368]\n",
      "loss: 0.524288  [83264/116368]\n",
      "loss: 0.534214  [89664/116368]\n",
      "loss: 0.364180  [96064/116368]\n",
      "loss: 0.300592  [102464/116368]\n",
      "loss: 0.480497  [108864/116368]\n",
      "loss: 0.460272  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.403501 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.322175  [   64/116368]\n",
      "loss: 0.318099  [ 6464/116368]\n",
      "loss: 0.448116  [12864/116368]\n",
      "loss: 0.276837  [19264/116368]\n",
      "loss: 0.447753  [25664/116368]\n",
      "loss: 0.461506  [32064/116368]\n",
      "loss: 0.451329  [38464/116368]\n",
      "loss: 0.577287  [44864/116368]\n",
      "loss: 0.389040  [51264/116368]\n",
      "loss: 0.283319  [57664/116368]\n",
      "loss: 0.603521  [64064/116368]\n",
      "loss: 0.264331  [70464/116368]\n",
      "loss: 0.340239  [76864/116368]\n",
      "loss: 0.491490  [83264/116368]\n",
      "loss: 0.410472  [89664/116368]\n",
      "loss: 0.441174  [96064/116368]\n",
      "loss: 0.567977  [102464/116368]\n",
      "loss: 0.682363  [108864/116368]\n",
      "loss: 0.396850  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.495745 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.553522  [   64/116368]\n",
      "loss: 0.429677  [ 6464/116368]\n",
      "loss: 0.441803  [12864/116368]\n",
      "loss: 0.376379  [19264/116368]\n",
      "loss: 0.465688  [25664/116368]\n",
      "loss: 0.422662  [32064/116368]\n",
      "loss: 0.265644  [38464/116368]\n",
      "loss: 0.292293  [44864/116368]\n",
      "loss: 0.342284  [51264/116368]\n",
      "loss: 0.524922  [57664/116368]\n",
      "loss: 0.303070  [64064/116368]\n",
      "loss: 0.270824  [70464/116368]\n",
      "loss: 0.370329  [76864/116368]\n",
      "loss: 0.478226  [83264/116368]\n",
      "loss: 0.456281  [89664/116368]\n",
      "loss: 0.434022  [96064/116368]\n",
      "loss: 0.417880  [102464/116368]\n",
      "loss: 0.357934  [108864/116368]\n",
      "loss: 0.436106  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.486987 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.455146  [   64/116368]\n",
      "loss: 0.359994  [ 6464/116368]\n",
      "loss: 0.406751  [12864/116368]\n",
      "loss: 0.402691  [19264/116368]\n",
      "loss: 0.407218  [25664/116368]\n",
      "loss: 0.570637  [32064/116368]\n",
      "loss: 0.403465  [38464/116368]\n",
      "loss: 0.334981  [44864/116368]\n",
      "loss: 0.398644  [51264/116368]\n",
      "loss: 0.319451  [57664/116368]\n",
      "loss: 0.357803  [64064/116368]\n",
      "loss: 0.403566  [70464/116368]\n",
      "loss: 0.451046  [76864/116368]\n",
      "loss: 0.400841  [83264/116368]\n",
      "loss: 0.411586  [89664/116368]\n",
      "loss: 0.225456  [96064/116368]\n",
      "loss: 0.454966  [102464/116368]\n",
      "loss: 0.325339  [108864/116368]\n",
      "loss: 0.369396  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.441994 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.436319  [   64/116368]\n",
      "loss: 0.430275  [ 6464/116368]\n",
      "loss: 0.455383  [12864/116368]\n",
      "loss: 0.358253  [19264/116368]\n",
      "loss: 0.386616  [25664/116368]\n",
      "loss: 0.436183  [32064/116368]\n",
      "loss: 0.361044  [38464/116368]\n",
      "loss: 0.272438  [44864/116368]\n",
      "loss: 0.388481  [51264/116368]\n",
      "loss: 0.386538  [57664/116368]\n",
      "loss: 0.407110  [64064/116368]\n",
      "loss: 0.678248  [70464/116368]\n",
      "loss: 0.436035  [76864/116368]\n",
      "loss: 0.438482  [83264/116368]\n",
      "loss: 0.443645  [89664/116368]\n",
      "loss: 0.405849  [96064/116368]\n",
      "loss: 0.366022  [102464/116368]\n",
      "loss: 0.386539  [108864/116368]\n",
      "loss: 0.541460  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.637602 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.662818  [   64/116368]\n",
      "loss: 0.256305  [ 6464/116368]\n",
      "loss: 0.456524  [12864/116368]\n",
      "loss: 0.339471  [19264/116368]\n",
      "loss: 0.465125  [25664/116368]\n",
      "loss: 0.456898  [32064/116368]\n",
      "loss: 0.399696  [38464/116368]\n",
      "loss: 0.368138  [44864/116368]\n",
      "loss: 0.527766  [51264/116368]\n",
      "loss: 0.350823  [57664/116368]\n",
      "loss: 0.387863  [64064/116368]\n",
      "loss: 0.403575  [70464/116368]\n",
      "loss: 0.425679  [76864/116368]\n",
      "loss: 0.381416  [83264/116368]\n",
      "loss: 0.396996  [89664/116368]\n",
      "loss: 0.435589  [96064/116368]\n",
      "loss: 0.441555  [102464/116368]\n",
      "loss: 0.520021  [108864/116368]\n",
      "loss: 0.363109  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.395113 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.446223  [   64/116368]\n",
      "loss: 0.294092  [ 6464/116368]\n",
      "loss: 0.321583  [12864/116368]\n",
      "loss: 0.446309  [19264/116368]\n",
      "loss: 0.256726  [25664/116368]\n",
      "loss: 0.293990  [32064/116368]\n",
      "loss: 0.363948  [38464/116368]\n",
      "loss: 0.505520  [44864/116368]\n",
      "loss: 0.451506  [51264/116368]\n",
      "loss: 0.404059  [57664/116368]\n",
      "loss: 0.466582  [64064/116368]\n",
      "loss: 0.292196  [70464/116368]\n",
      "loss: 0.304887  [76864/116368]\n",
      "loss: 0.439316  [83264/116368]\n",
      "loss: 0.436096  [89664/116368]\n",
      "loss: 0.405350  [96064/116368]\n",
      "loss: 0.425919  [102464/116368]\n",
      "loss: 0.287226  [108864/116368]\n",
      "loss: 0.335741  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.494603 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.221864  [   64/116368]\n",
      "loss: 0.299273  [ 6464/116368]\n",
      "loss: 0.344516  [12864/116368]\n",
      "loss: 0.422097  [19264/116368]\n",
      "loss: 0.449445  [25664/116368]\n",
      "loss: 0.460798  [32064/116368]\n",
      "loss: 0.387966  [38464/116368]\n",
      "loss: 0.329035  [44864/116368]\n",
      "loss: 0.426920  [51264/116368]\n",
      "loss: 0.410623  [57664/116368]\n",
      "loss: 0.434529  [64064/116368]\n",
      "loss: 0.389361  [70464/116368]\n",
      "loss: 0.288966  [76864/116368]\n",
      "loss: 0.522228  [83264/116368]\n",
      "loss: 0.396207  [89664/116368]\n",
      "loss: 0.324013  [96064/116368]\n",
      "loss: 0.368384  [102464/116368]\n",
      "loss: 0.300493  [108864/116368]\n",
      "loss: 0.444334  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.435275 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.342951  [   64/116368]\n",
      "loss: 0.509971  [ 6464/116368]\n",
      "loss: 0.377103  [12864/116368]\n",
      "loss: 0.335299  [19264/116368]\n",
      "loss: 0.477432  [25664/116368]\n",
      "loss: 0.441190  [32064/116368]\n",
      "loss: 0.394458  [38464/116368]\n",
      "loss: 0.452979  [44864/116368]\n",
      "loss: 0.407768  [51264/116368]\n",
      "loss: 0.285791  [57664/116368]\n",
      "loss: 0.401880  [64064/116368]\n",
      "loss: 0.431008  [70464/116368]\n",
      "loss: 0.480633  [76864/116368]\n",
      "loss: 0.448296  [83264/116368]\n",
      "loss: 0.351156  [89664/116368]\n",
      "loss: 0.504929  [96064/116368]\n",
      "loss: 0.269136  [102464/116368]\n",
      "loss: 0.304199  [108864/116368]\n",
      "loss: 0.438785  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.431391 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.524122  [   64/116368]\n",
      "loss: 0.346612  [ 6464/116368]\n",
      "loss: 0.396633  [12864/116368]\n",
      "loss: 0.300398  [19264/116368]\n",
      "loss: 0.532194  [25664/116368]\n",
      "loss: 0.420628  [32064/116368]\n",
      "loss: 0.373911  [38464/116368]\n",
      "loss: 0.449234  [44864/116368]\n",
      "loss: 0.334253  [51264/116368]\n",
      "loss: 0.294982  [57664/116368]\n",
      "loss: 0.351878  [64064/116368]\n",
      "loss: 0.307147  [70464/116368]\n",
      "loss: 0.399000  [76864/116368]\n",
      "loss: 0.388579  [83264/116368]\n",
      "loss: 0.467557  [89664/116368]\n",
      "loss: 0.454422  [96064/116368]\n",
      "loss: 0.357690  [102464/116368]\n",
      "loss: 0.471483  [108864/116368]\n",
      "loss: 0.363981  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.394605 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.294805  [   64/116368]\n",
      "loss: 0.548101  [ 6464/116368]\n",
      "loss: 0.422982  [12864/116368]\n",
      "loss: 0.465283  [19264/116368]\n",
      "loss: 0.453538  [25664/116368]\n",
      "loss: 0.570153  [32064/116368]\n",
      "loss: 0.476620  [38464/116368]\n",
      "loss: 0.380267  [44864/116368]\n",
      "loss: 0.450712  [51264/116368]\n",
      "loss: 0.387730  [57664/116368]\n",
      "loss: 0.389897  [64064/116368]\n",
      "loss: 0.435831  [70464/116368]\n",
      "loss: 0.351286  [76864/116368]\n",
      "loss: 0.417415  [83264/116368]\n",
      "loss: 0.368118  [89664/116368]\n",
      "loss: 0.422010  [96064/116368]\n",
      "loss: 0.369002  [102464/116368]\n",
      "loss: 0.305579  [108864/116368]\n",
      "loss: 0.352245  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.409403 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.353411  [   64/116368]\n",
      "loss: 0.267358  [ 6464/116368]\n",
      "loss: 0.373382  [12864/116368]\n",
      "loss: 0.438185  [19264/116368]\n",
      "loss: 0.494164  [25664/116368]\n",
      "loss: 0.427790  [32064/116368]\n",
      "loss: 0.444358  [38464/116368]\n",
      "loss: 0.391727  [44864/116368]\n",
      "loss: 0.361639  [51264/116368]\n",
      "loss: 0.315006  [57664/116368]\n",
      "loss: 0.417546  [64064/116368]\n",
      "loss: 0.317663  [70464/116368]\n",
      "loss: 0.464252  [76864/116368]\n",
      "loss: 0.295645  [83264/116368]\n",
      "loss: 0.356886  [89664/116368]\n",
      "loss: 0.412770  [96064/116368]\n",
      "loss: 0.303342  [102464/116368]\n",
      "loss: 0.444043  [108864/116368]\n",
      "loss: 0.354676  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.842814 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.737661  [   64/116368]\n",
      "loss: 0.256020  [ 6464/116368]\n",
      "loss: 0.333919  [12864/116368]\n",
      "loss: 0.501181  [19264/116368]\n",
      "loss: 0.355755  [25664/116368]\n",
      "loss: 0.371907  [32064/116368]\n",
      "loss: 0.338708  [38464/116368]\n",
      "loss: 0.434268  [44864/116368]\n",
      "loss: 0.512504  [51264/116368]\n",
      "loss: 0.466468  [57664/116368]\n",
      "loss: 0.536314  [64064/116368]\n",
      "loss: 0.455802  [70464/116368]\n",
      "loss: 0.285316  [76864/116368]\n",
      "loss: 0.421378  [83264/116368]\n",
      "loss: 0.395468  [89664/116368]\n",
      "loss: 0.416003  [96064/116368]\n",
      "loss: 0.325755  [102464/116368]\n",
      "loss: 0.393306  [108864/116368]\n",
      "loss: 0.467160  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.385575 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.468571  [   64/116368]\n",
      "loss: 0.416993  [ 6464/116368]\n",
      "loss: 0.561641  [12864/116368]\n",
      "loss: 0.365459  [19264/116368]\n",
      "loss: 0.495529  [25664/116368]\n",
      "loss: 0.328846  [32064/116368]\n",
      "loss: 0.318206  [38464/116368]\n",
      "loss: 0.329462  [44864/116368]\n",
      "loss: 0.472667  [51264/116368]\n",
      "loss: 0.341438  [57664/116368]\n",
      "loss: 0.382910  [64064/116368]\n",
      "loss: 0.408927  [70464/116368]\n",
      "loss: 0.284692  [76864/116368]\n",
      "loss: 0.386368  [83264/116368]\n",
      "loss: 0.269593  [89664/116368]\n",
      "loss: 0.384316  [96064/116368]\n",
      "loss: 0.341885  [102464/116368]\n",
      "loss: 0.458547  [108864/116368]\n",
      "loss: 0.311183  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.397052 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.474402  [   64/116368]\n",
      "loss: 0.345202  [ 6464/116368]\n",
      "loss: 0.369720  [12864/116368]\n",
      "loss: 0.342458  [19264/116368]\n",
      "loss: 0.376889  [25664/116368]\n",
      "loss: 0.495881  [32064/116368]\n",
      "loss: 0.363940  [38464/116368]\n",
      "loss: 0.453418  [44864/116368]\n",
      "loss: 0.437099  [51264/116368]\n",
      "loss: 0.278077  [57664/116368]\n",
      "loss: 0.435188  [64064/116368]\n",
      "loss: 0.409179  [70464/116368]\n",
      "loss: 0.282311  [76864/116368]\n",
      "loss: 0.319907  [83264/116368]\n",
      "loss: 0.456667  [89664/116368]\n",
      "loss: 0.260335  [96064/116368]\n",
      "loss: 0.346572  [102464/116368]\n",
      "loss: 0.452501  [108864/116368]\n",
      "loss: 0.352494  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.401588 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.406225  [   64/116368]\n",
      "loss: 0.505559  [ 6464/116368]\n",
      "loss: 0.539140  [12864/116368]\n",
      "loss: 0.504399  [19264/116368]\n",
      "loss: 0.448077  [25664/116368]\n",
      "loss: 0.346515  [32064/116368]\n",
      "loss: 0.559008  [38464/116368]\n",
      "loss: 0.428465  [44864/116368]\n",
      "loss: 0.420200  [51264/116368]\n",
      "loss: 0.292404  [57664/116368]\n",
      "loss: 0.357025  [64064/116368]\n",
      "loss: 0.454020  [70464/116368]\n",
      "loss: 0.418835  [76864/116368]\n",
      "loss: 0.396286  [83264/116368]\n",
      "loss: 0.387916  [89664/116368]\n",
      "loss: 0.433537  [96064/116368]\n",
      "loss: 0.247482  [102464/116368]\n",
      "loss: 0.284942  [108864/116368]\n",
      "loss: 0.355291  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.386945 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# epochs = 5\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c0bb2e4",
   "metadata": {
    "_cell_guid": "9030f2af-84b7-47e4-aca2-d76722e61de7",
    "_uuid": "9ad381a8-fc6f-4c7a-95cd-ce248119354d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:56:56.212616Z",
     "iopub.status.busy": "2024-04-02T04:56:56.211946Z",
     "iopub.status.idle": "2024-04-02T04:56:56.587256Z",
     "shell.execute_reply": "2024-04-02T04:56:56.586376Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.400784,
     "end_time": "2024-04-02T04:56:56.589425",
     "exception": false,
     "start_time": "2024-04-02T04:56:56.188641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy : 49.79%\n"
     ]
    }
   ],
   "source": [
    "model.eval()    # í‰ê°€ì‹œì—ëŠ” dropoutì´ OFF ëœë‹¤.\n",
    "correct = 0\n",
    "for data, target in test_dataloader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1]\n",
    "    correct += prediction.eq(target.data).sum()\n",
    "print('Test set Accuracy : {:.2f}%'.format(correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17195fd5",
   "metadata": {
    "_cell_guid": "95789f9a-3878-4917-992c-474fe47fcf54",
    "_uuid": "e353ad7a-c659-4c33-a041-e7ea1328db55",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:56:56.635068Z",
     "iopub.status.busy": "2024-04-02T04:56:56.634405Z",
     "iopub.status.idle": "2024-04-02T04:56:56.640273Z",
     "shell.execute_reply": "2024-04-02T04:56:56.639455Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030939,
     "end_time": "2024-04-02T04:56:56.642454",
     "exception": false,
     "start_time": "2024-04-02T04:56:56.611515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Optimizer', 'Learning Rate', 'Train Loss', 'Val Loss', 'Test Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "757976fe",
   "metadata": {
    "_cell_guid": "52af11b2-adae-47a8-8844-549b44ad4305",
    "_uuid": "1b348984-e2b9-4d3c-9443-302469d7dcd0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-02T04:56:56.689863Z",
     "iopub.status.busy": "2024-04-02T04:56:56.689215Z",
     "iopub.status.idle": "2024-04-02T05:20:42.583014Z",
     "shell.execute_reply": "2024-04-02T05:20:42.581883Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1425.919993,
     "end_time": "2024-04-02T05:20:42.585310",
     "exception": false,
     "start_time": "2024-04-02T04:56:56.665317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with optimizer: SGD, Learning Rate: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.286848  [   64/116368]\n",
      "loss: 13.254337  [ 6464/116368]\n",
      "loss: 19.893282  [12864/116368]\n",
      "loss: 11.530470  [19264/116368]\n",
      "loss: 13.250433  [25664/116368]\n",
      "loss: 12.449374  [32064/116368]\n",
      "loss: 15.027278  [38464/116368]\n",
      "loss: 13.419075  [44864/116368]\n",
      "loss: 7.434869  [51264/116368]\n",
      "loss: 14.076657  [57664/116368]\n",
      "loss: 12.417061  [64064/116368]\n",
      "loss: 12.411246  [70464/116368]\n",
      "loss: 9.231548  [76864/116368]\n",
      "loss: 12.407146  [83264/116368]\n",
      "loss: 8.303185  [89664/116368]\n",
      "loss: 11.717695  [96064/116368]\n",
      "loss: 9.156640  [102464/116368]\n",
      "loss: 10.800274  [108864/116368]\n",
      "loss: 9.936167  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 10.756663  [   64/116368]\n",
      "loss: 9.957947  [ 6464/116368]\n",
      "loss: 14.935062  [12864/116368]\n",
      "loss: 10.784765  [19264/116368]\n",
      "loss: 12.473181  [25664/116368]\n",
      "loss: 16.631443  [32064/116368]\n",
      "loss: 8.296723  [38464/116368]\n",
      "loss: 12.435339  [44864/116368]\n",
      "loss: 8.312784  [51264/116368]\n",
      "loss: 10.719667  [57664/116368]\n",
      "loss: 9.965854  [64064/116368]\n",
      "loss: 15.745440  [70464/116368]\n",
      "loss: 13.294817  [76864/116368]\n",
      "loss: 11.665992  [83264/116368]\n",
      "loss: 14.174256  [89664/116368]\n",
      "loss: 11.499650  [96064/116368]\n",
      "loss: 13.217005  [102464/116368]\n",
      "loss: 5.856810  [108864/116368]\n",
      "loss: 9.134395  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 6.648757  [   64/116368]\n",
      "loss: 12.449574  [ 6464/116368]\n",
      "loss: 15.797402  [12864/116368]\n",
      "loss: 13.343510  [19264/116368]\n",
      "loss: 6.637943  [25664/116368]\n",
      "loss: 11.661948  [32064/116368]\n",
      "loss: 7.547908  [38464/116368]\n",
      "loss: 14.172264  [44864/116368]\n",
      "loss: 10.816477  [51264/116368]\n",
      "loss: 11.714948  [57664/116368]\n",
      "loss: 7.419371  [64064/116368]\n",
      "loss: 8.268819  [70464/116368]\n",
      "loss: 9.975368  [76864/116368]\n",
      "loss: 9.193794  [83264/116368]\n",
      "loss: 11.638211  [89664/116368]\n",
      "loss: 14.935292  [96064/116368]\n",
      "loss: 12.480768  [102464/116368]\n",
      "loss: 8.356376  [108864/116368]\n",
      "loss: 10.736367  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 9.964167  [   64/116368]\n",
      "loss: 12.473404  [ 6464/116368]\n",
      "loss: 10.009824  [12864/116368]\n",
      "loss: 14.171291  [19264/116368]\n",
      "loss: 11.600141  [25664/116368]\n",
      "loss: 8.336992  [32064/116368]\n",
      "loss: 19.124247  [38464/116368]\n",
      "loss: 6.625516  [44864/116368]\n",
      "loss: 10.011071  [51264/116368]\n",
      "loss: 7.458282  [57664/116368]\n",
      "loss: 14.103195  [64064/116368]\n",
      "loss: 9.105375  [70464/116368]\n",
      "loss: 11.667487  [76864/116368]\n",
      "loss: 14.097095  [83264/116368]\n",
      "loss: 16.631912  [89664/116368]\n",
      "loss: 9.953135  [96064/116368]\n",
      "loss: 13.403620  [102464/116368]\n",
      "loss: 14.973885  [108864/116368]\n",
      "loss: 11.718851  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 9.123145  [   64/116368]\n",
      "loss: 14.106778  [ 6464/116368]\n",
      "loss: 9.185310  [12864/116368]\n",
      "loss: 10.825058  [19264/116368]\n",
      "loss: 9.952541  [25664/116368]\n",
      "loss: 10.806267  [32064/116368]\n",
      "loss: 6.641284  [38464/116368]\n",
      "loss: 8.312218  [44864/116368]\n",
      "loss: 12.501414  [51264/116368]\n",
      "loss: 9.958039  [57664/116368]\n",
      "loss: 17.414555  [64064/116368]\n",
      "loss: 11.656817  [70464/116368]\n",
      "loss: 9.142920  [76864/116368]\n",
      "loss: 11.619776  [83264/116368]\n",
      "loss: 11.535911  [89664/116368]\n",
      "loss: 15.808468  [96064/116368]\n",
      "loss: 9.078928  [102464/116368]\n",
      "loss: 11.567490  [108864/116368]\n",
      "loss: 11.607225  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 12.379377  [   64/116368]\n",
      "loss: 8.271847  [ 6464/116368]\n",
      "loss: 14.210933  [12864/116368]\n",
      "loss: 10.033269  [19264/116368]\n",
      "loss: 11.659602  [25664/116368]\n",
      "loss: 13.307512  [32064/116368]\n",
      "loss: 17.502260  [38464/116368]\n",
      "loss: 11.610080  [44864/116368]\n",
      "loss: 11.565384  [51264/116368]\n",
      "loss: 14.119535  [57664/116368]\n",
      "loss: 7.457398  [64064/116368]\n",
      "loss: 10.845078  [70464/116368]\n",
      "loss: 9.176843  [76864/116368]\n",
      "loss: 14.222902  [83264/116368]\n",
      "loss: 20.717585  [89664/116368]\n",
      "loss: 12.381039  [96064/116368]\n",
      "loss: 10.790907  [102464/116368]\n",
      "loss: 7.442761  [108864/116368]\n",
      "loss: 9.144228  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 15.773431  [   64/116368]\n",
      "loss: 10.849380  [ 6464/116368]\n",
      "loss: 10.762015  [12864/116368]\n",
      "loss: 9.934214  [19264/116368]\n",
      "loss: 10.781315  [25664/116368]\n",
      "loss: 13.324371  [32064/116368]\n",
      "loss: 9.913985  [38464/116368]\n",
      "loss: 9.169714  [44864/116368]\n",
      "loss: 8.299639  [51264/116368]\n",
      "loss: 8.287508  [57664/116368]\n",
      "loss: 15.122885  [64064/116368]\n",
      "loss: 13.309427  [70464/116368]\n",
      "loss: 9.184334  [76864/116368]\n",
      "loss: 9.940641  [83264/116368]\n",
      "loss: 15.666158  [89664/116368]\n",
      "loss: 12.500814  [96064/116368]\n",
      "loss: 12.567848  [102464/116368]\n",
      "loss: 9.954768  [108864/116368]\n",
      "loss: 9.155234  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 8.303497  [   64/116368]\n",
      "loss: 13.273825  [ 6464/116368]\n",
      "loss: 8.301279  [12864/116368]\n",
      "loss: 11.597926  [19264/116368]\n",
      "loss: 14.190040  [25664/116368]\n",
      "loss: 14.951262  [32064/116368]\n",
      "loss: 8.286714  [38464/116368]\n",
      "loss: 13.333555  [44864/116368]\n",
      "loss: 7.503144  [51264/116368]\n",
      "loss: 8.226072  [57664/116368]\n",
      "loss: 14.901340  [64064/116368]\n",
      "loss: 16.556150  [70464/116368]\n",
      "loss: 11.660711  [76864/116368]\n",
      "loss: 14.031311  [83264/116368]\n",
      "loss: 11.604979  [89664/116368]\n",
      "loss: 18.338940  [96064/116368]\n",
      "loss: 14.062141  [102464/116368]\n",
      "loss: 8.332027  [108864/116368]\n",
      "loss: 13.351392  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 13.264273  [   64/116368]\n",
      "loss: 11.616406  [ 6464/116368]\n",
      "loss: 15.834074  [12864/116368]\n",
      "loss: 9.193820  [19264/116368]\n",
      "loss: 5.840011  [25664/116368]\n",
      "loss: 14.109463  [32064/116368]\n",
      "loss: 9.986494  [38464/116368]\n",
      "loss: 14.162937  [44864/116368]\n",
      "loss: 15.819081  [51264/116368]\n",
      "loss: 15.007332  [57664/116368]\n",
      "loss: 11.685431  [64064/116368]\n",
      "loss: 9.918701  [70464/116368]\n",
      "loss: 8.294037  [76864/116368]\n",
      "loss: 7.418017  [83264/116368]\n",
      "loss: 14.256193  [89664/116368]\n",
      "loss: 8.274822  [96064/116368]\n",
      "loss: 9.967036  [102464/116368]\n",
      "loss: 8.280128  [108864/116368]\n",
      "loss: 10.910453  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 13.346926  [   64/116368]\n",
      "loss: 12.447769  [ 6464/116368]\n",
      "loss: 8.286736  [12864/116368]\n",
      "loss: 7.534567  [19264/116368]\n",
      "loss: 11.521902  [25664/116368]\n",
      "loss: 15.809651  [32064/116368]\n",
      "loss: 8.256443  [38464/116368]\n",
      "loss: 12.503806  [44864/116368]\n",
      "loss: 11.664989  [51264/116368]\n",
      "loss: 10.808228  [57664/116368]\n",
      "loss: 9.955980  [64064/116368]\n",
      "loss: 11.641969  [70464/116368]\n",
      "loss: 10.755890  [76864/116368]\n",
      "loss: 17.472473  [83264/116368]\n",
      "loss: 10.772168  [89664/116368]\n",
      "loss: 14.938768  [96064/116368]\n",
      "loss: 11.646789  [102464/116368]\n",
      "loss: 12.423178  [108864/116368]\n",
      "loss: 8.229021  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 14.114731  [   64/116368]\n",
      "loss: 9.099079  [ 6464/116368]\n",
      "loss: 4.152300  [12864/116368]\n",
      "loss: 9.969692  [19264/116368]\n",
      "loss: 12.413641  [25664/116368]\n",
      "loss: 12.377838  [32064/116368]\n",
      "loss: 14.055032  [38464/116368]\n",
      "loss: 14.105314  [44864/116368]\n",
      "loss: 16.558443  [51264/116368]\n",
      "loss: 9.218477  [57664/116368]\n",
      "loss: 13.288681  [64064/116368]\n",
      "loss: 14.984985  [70464/116368]\n",
      "loss: 8.358536  [76864/116368]\n",
      "loss: 9.991682  [83264/116368]\n",
      "loss: 11.670180  [89664/116368]\n",
      "loss: 18.361500  [96064/116368]\n",
      "loss: 7.504463  [102464/116368]\n",
      "loss: 14.948621  [108864/116368]\n",
      "loss: 10.801130  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 12.468568  [   64/116368]\n",
      "loss: 12.406405  [ 6464/116368]\n",
      "loss: 7.529243  [12864/116368]\n",
      "loss: 8.308097  [19264/116368]\n",
      "loss: 10.008575  [25664/116368]\n",
      "loss: 9.213214  [32064/116368]\n",
      "loss: 9.109116  [38464/116368]\n",
      "loss: 9.231449  [44864/116368]\n",
      "loss: 7.443789  [51264/116368]\n",
      "loss: 7.529879  [57664/116368]\n",
      "loss: 15.792021  [64064/116368]\n",
      "loss: 18.208042  [70464/116368]\n",
      "loss: 5.836686  [76864/116368]\n",
      "loss: 13.338189  [83264/116368]\n",
      "loss: 13.246786  [89664/116368]\n",
      "loss: 10.862164  [96064/116368]\n",
      "loss: 10.744346  [102464/116368]\n",
      "loss: 9.953959  [108864/116368]\n",
      "loss: 12.405968  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 9.165665  [   64/116368]\n",
      "loss: 9.936852  [ 6464/116368]\n",
      "loss: 11.602065  [12864/116368]\n",
      "loss: 7.468461  [19264/116368]\n",
      "loss: 10.000570  [25664/116368]\n",
      "loss: 11.697001  [32064/116368]\n",
      "loss: 9.184898  [38464/116368]\n",
      "loss: 11.660908  [44864/116368]\n",
      "loss: 11.604978  [51264/116368]\n",
      "loss: 12.377584  [57664/116368]\n",
      "loss: 9.989119  [64064/116368]\n",
      "loss: 10.781260  [70464/116368]\n",
      "loss: 13.306686  [76864/116368]\n",
      "loss: 13.278628  [83264/116368]\n",
      "loss: 7.485468  [89664/116368]\n",
      "loss: 10.860906  [96064/116368]\n",
      "loss: 14.061560  [102464/116368]\n",
      "loss: 17.489590  [108864/116368]\n",
      "loss: 9.989620  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 6.690234  [   64/116368]\n",
      "loss: 14.962015  [ 6464/116368]\n",
      "loss: 11.668608  [12864/116368]\n",
      "loss: 10.024033  [19264/116368]\n",
      "loss: 9.945147  [25664/116368]\n",
      "loss: 13.203922  [32064/116368]\n",
      "loss: 13.311863  [38464/116368]\n",
      "loss: 14.084709  [44864/116368]\n",
      "loss: 13.248189  [51264/116368]\n",
      "loss: 13.364324  [57664/116368]\n",
      "loss: 15.015104  [64064/116368]\n",
      "loss: 13.383045  [70464/116368]\n",
      "loss: 8.374279  [76864/116368]\n",
      "loss: 14.118107  [83264/116368]\n",
      "loss: 9.125282  [89664/116368]\n",
      "loss: 12.569267  [96064/116368]\n",
      "loss: 17.491280  [102464/116368]\n",
      "loss: 8.294479  [108864/116368]\n",
      "loss: 11.626097  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 9.948267  [   64/116368]\n",
      "loss: 10.759286  [ 6464/116368]\n",
      "loss: 10.775202  [12864/116368]\n",
      "loss: 10.848298  [19264/116368]\n",
      "loss: 12.528775  [25664/116368]\n",
      "loss: 15.020408  [32064/116368]\n",
      "loss: 11.687409  [38464/116368]\n",
      "loss: 8.301308  [44864/116368]\n",
      "loss: 14.912785  [51264/116368]\n",
      "loss: 9.918461  [57664/116368]\n",
      "loss: 10.023795  [64064/116368]\n",
      "loss: 11.696732  [70464/116368]\n",
      "loss: 9.976906  [76864/116368]\n",
      "loss: 10.852168  [83264/116368]\n",
      "loss: 12.449289  [89664/116368]\n",
      "loss: 10.800589  [96064/116368]\n",
      "loss: 13.351759  [102464/116368]\n",
      "loss: 9.890642  [108864/116368]\n",
      "loss: 8.242279  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 12.529369  [   64/116368]\n",
      "loss: 12.466653  [ 6464/116368]\n",
      "loss: 10.798631  [12864/116368]\n",
      "loss: 10.770466  [19264/116368]\n",
      "loss: 9.964419  [25664/116368]\n",
      "loss: 14.036263  [32064/116368]\n",
      "loss: 16.516476  [38464/116368]\n",
      "loss: 9.872755  [44864/116368]\n",
      "loss: 10.851953  [51264/116368]\n",
      "loss: 12.500710  [57664/116368]\n",
      "loss: 15.817583  [64064/116368]\n",
      "loss: 10.885376  [70464/116368]\n",
      "loss: 14.161798  [76864/116368]\n",
      "loss: 7.461671  [83264/116368]\n",
      "loss: 10.797159  [89664/116368]\n",
      "loss: 10.665925  [96064/116368]\n",
      "loss: 15.761604  [102464/116368]\n",
      "loss: 9.054808  [108864/116368]\n",
      "loss: 12.487421  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 12.395676  [   64/116368]\n",
      "loss: 9.101141  [ 6464/116368]\n",
      "loss: 13.321440  [12864/116368]\n",
      "loss: 10.813283  [19264/116368]\n",
      "loss: 6.619683  [25664/116368]\n",
      "loss: 9.050478  [32064/116368]\n",
      "loss: 11.664064  [38464/116368]\n",
      "loss: 14.977388  [44864/116368]\n",
      "loss: 2.534280  [51264/116368]\n",
      "loss: 13.328292  [57664/116368]\n",
      "loss: 10.858938  [64064/116368]\n",
      "loss: 10.865433  [70464/116368]\n",
      "loss: 16.588659  [76864/116368]\n",
      "loss: 5.819656  [83264/116368]\n",
      "loss: 11.694601  [89664/116368]\n",
      "loss: 10.867435  [96064/116368]\n",
      "loss: 9.926959  [102464/116368]\n",
      "loss: 13.185548  [108864/116368]\n",
      "loss: 11.524157  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 12.470020  [   64/116368]\n",
      "loss: 8.349911  [ 6464/116368]\n",
      "loss: 8.330437  [12864/116368]\n",
      "loss: 11.648707  [19264/116368]\n",
      "loss: 14.194678  [25664/116368]\n",
      "loss: 14.980169  [32064/116368]\n",
      "loss: 10.836722  [38464/116368]\n",
      "loss: 9.901554  [44864/116368]\n",
      "loss: 8.329455  [51264/116368]\n",
      "loss: 10.826195  [57664/116368]\n",
      "loss: 14.890049  [64064/116368]\n",
      "loss: 13.322768  [70464/116368]\n",
      "loss: 10.812022  [76864/116368]\n",
      "loss: 10.920916  [83264/116368]\n",
      "loss: 8.291448  [89664/116368]\n",
      "loss: 8.318839  [96064/116368]\n",
      "loss: 12.395020  [102464/116368]\n",
      "loss: 14.097178  [108864/116368]\n",
      "loss: 9.959160  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 14.116162  [   64/116368]\n",
      "loss: 14.919470  [ 6464/116368]\n",
      "loss: 11.642773  [12864/116368]\n",
      "loss: 9.144569  [19264/116368]\n",
      "loss: 15.785951  [25664/116368]\n",
      "loss: 10.831369  [32064/116368]\n",
      "loss: 14.934185  [38464/116368]\n",
      "loss: 9.182675  [44864/116368]\n",
      "loss: 14.215497  [51264/116368]\n",
      "loss: 16.738880  [57664/116368]\n",
      "loss: 6.652075  [64064/116368]\n",
      "loss: 17.346548  [70464/116368]\n",
      "loss: 13.209010  [76864/116368]\n",
      "loss: 6.646581  [83264/116368]\n",
      "loss: 14.991503  [89664/116368]\n",
      "loss: 12.490975  [96064/116368]\n",
      "loss: 15.772850  [102464/116368]\n",
      "loss: 9.108809  [108864/116368]\n",
      "loss: 7.476448  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 11.679905  [   64/116368]\n",
      "loss: 9.174755  [ 6464/116368]\n",
      "loss: 14.122540  [12864/116368]\n",
      "loss: 11.624214  [19264/116368]\n",
      "loss: 10.827586  [25664/116368]\n",
      "loss: 14.778934  [32064/116368]\n",
      "loss: 12.527964  [38464/116368]\n",
      "loss: 11.577620  [44864/116368]\n",
      "loss: 12.411231  [51264/116368]\n",
      "loss: 9.959609  [57664/116368]\n",
      "loss: 10.781279  [64064/116368]\n",
      "loss: 9.949906  [70464/116368]\n",
      "loss: 11.608785  [76864/116368]\n",
      "loss: 16.568111  [83264/116368]\n",
      "loss: 15.791768  [89664/116368]\n",
      "loss: 9.176001  [96064/116368]\n",
      "loss: 12.456981  [102464/116368]\n",
      "loss: 9.184270  [108864/116368]\n",
      "loss: 16.594391  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: SGD, Learning Rate: 0.005\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 11.641365  [   64/116368]\n",
      "loss: 11.639532  [ 6464/116368]\n",
      "loss: 9.130485  [12864/116368]\n",
      "loss: 10.823643  [19264/116368]\n",
      "loss: 5.827137  [25664/116368]\n",
      "loss: 12.473549  [32064/116368]\n",
      "loss: 13.265707  [38464/116368]\n",
      "loss: 14.093817  [44864/116368]\n",
      "loss: 7.447302  [51264/116368]\n",
      "loss: 14.187442  [57664/116368]\n",
      "loss: 14.914036  [64064/116368]\n",
      "loss: 15.740973  [70464/116368]\n",
      "loss: 10.856646  [76864/116368]\n",
      "loss: 12.384736  [83264/116368]\n",
      "loss: 10.045135  [89664/116368]\n",
      "loss: 6.669682  [96064/116368]\n",
      "loss: 20.021578  [102464/116368]\n",
      "loss: 6.666254  [108864/116368]\n",
      "loss: 13.164205  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 11.634183  [   64/116368]\n",
      "loss: 10.845740  [ 6464/116368]\n",
      "loss: 9.117468  [12864/116368]\n",
      "loss: 11.637888  [19264/116368]\n",
      "loss: 11.597747  [25664/116368]\n",
      "loss: 10.752664  [32064/116368]\n",
      "loss: 12.554010  [38464/116368]\n",
      "loss: 8.260582  [44864/116368]\n",
      "loss: 12.497391  [51264/116368]\n",
      "loss: 8.359953  [57664/116368]\n",
      "loss: 10.777151  [64064/116368]\n",
      "loss: 9.064802  [70464/116368]\n",
      "loss: 9.942202  [76864/116368]\n",
      "loss: 9.975171  [83264/116368]\n",
      "loss: 15.807102  [89664/116368]\n",
      "loss: 11.676961  [96064/116368]\n",
      "loss: 10.733708  [102464/116368]\n",
      "loss: 12.439302  [108864/116368]\n",
      "loss: 11.583403  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 14.899032  [   64/116368]\n",
      "loss: 14.296138  [ 6464/116368]\n",
      "loss: 6.625863  [12864/116368]\n",
      "loss: 13.351165  [19264/116368]\n",
      "loss: 10.856216  [25664/116368]\n",
      "loss: 11.671480  [32064/116368]\n",
      "loss: 7.537450  [38464/116368]\n",
      "loss: 11.654789  [44864/116368]\n",
      "loss: 10.037750  [51264/116368]\n",
      "loss: 9.990519  [57664/116368]\n",
      "loss: 9.940443  [64064/116368]\n",
      "loss: 6.655747  [70464/116368]\n",
      "loss: 16.652996  [76864/116368]\n",
      "loss: 12.465487  [83264/116368]\n",
      "loss: 12.457832  [89664/116368]\n",
      "loss: 14.162543  [96064/116368]\n",
      "loss: 14.867285  [102464/116368]\n",
      "loss: 9.992979  [108864/116368]\n",
      "loss: 9.104297  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 10.041471  [   64/116368]\n",
      "loss: 17.451048  [ 6464/116368]\n",
      "loss: 15.783814  [12864/116368]\n",
      "loss: 10.699863  [19264/116368]\n",
      "loss: 13.306205  [25664/116368]\n",
      "loss: 17.400978  [32064/116368]\n",
      "loss: 16.507660  [38464/116368]\n",
      "loss: 9.121219  [44864/116368]\n",
      "loss: 13.304299  [51264/116368]\n",
      "loss: 7.456308  [57664/116368]\n",
      "loss: 10.834067  [64064/116368]\n",
      "loss: 13.337967  [70464/116368]\n",
      "loss: 12.535271  [76864/116368]\n",
      "loss: 11.617087  [83264/116368]\n",
      "loss: 11.527320  [89664/116368]\n",
      "loss: 12.438845  [96064/116368]\n",
      "loss: 14.983762  [102464/116368]\n",
      "loss: 9.951706  [108864/116368]\n",
      "loss: 8.306437  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 12.475435  [   64/116368]\n",
      "loss: 13.419323  [ 6464/116368]\n",
      "loss: 8.347947  [12864/116368]\n",
      "loss: 8.351572  [19264/116368]\n",
      "loss: 11.669803  [25664/116368]\n",
      "loss: 8.227262  [32064/116368]\n",
      "loss: 8.295768  [38464/116368]\n",
      "loss: 10.764966  [44864/116368]\n",
      "loss: 9.139782  [51264/116368]\n",
      "loss: 19.114462  [57664/116368]\n",
      "loss: 14.217932  [64064/116368]\n",
      "loss: 10.779795  [70464/116368]\n",
      "loss: 10.814787  [76864/116368]\n",
      "loss: 12.455275  [83264/116368]\n",
      "loss: 9.967903  [89664/116368]\n",
      "loss: 14.160123  [96064/116368]\n",
      "loss: 9.031702  [102464/116368]\n",
      "loss: 14.942894  [108864/116368]\n",
      "loss: 7.590942  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 14.975428  [   64/116368]\n",
      "loss: 11.605577  [ 6464/116368]\n",
      "loss: 10.838755  [12864/116368]\n",
      "loss: 17.435080  [19264/116368]\n",
      "loss: 11.685795  [25664/116368]\n",
      "loss: 9.994979  [32064/116368]\n",
      "loss: 12.493865  [38464/116368]\n",
      "loss: 13.361568  [44864/116368]\n",
      "loss: 8.360307  [51264/116368]\n",
      "loss: 13.416085  [57664/116368]\n",
      "loss: 14.889652  [64064/116368]\n",
      "loss: 5.741632  [70464/116368]\n",
      "loss: 16.563807  [76864/116368]\n",
      "loss: 14.196318  [83264/116368]\n",
      "loss: 9.144930  [89664/116368]\n",
      "loss: 10.753814  [96064/116368]\n",
      "loss: 14.051546  [102464/116368]\n",
      "loss: 17.445433  [108864/116368]\n",
      "loss: 12.450764  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 6.675216  [   64/116368]\n",
      "loss: 10.837685  [ 6464/116368]\n",
      "loss: 13.429893  [12864/116368]\n",
      "loss: 12.512478  [19264/116368]\n",
      "loss: 13.263088  [25664/116368]\n",
      "loss: 14.207652  [32064/116368]\n",
      "loss: 10.781590  [38464/116368]\n",
      "loss: 10.920280  [44864/116368]\n",
      "loss: 11.540049  [51264/116368]\n",
      "loss: 9.913614  [57664/116368]\n",
      "loss: 11.641406  [64064/116368]\n",
      "loss: 14.183478  [70464/116368]\n",
      "loss: 13.195504  [76864/116368]\n",
      "loss: 14.928803  [83264/116368]\n",
      "loss: 13.297177  [89664/116368]\n",
      "loss: 10.835680  [96064/116368]\n",
      "loss: 10.829329  [102464/116368]\n",
      "loss: 9.939745  [108864/116368]\n",
      "loss: 9.144518  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 10.810190  [   64/116368]\n",
      "loss: 14.959136  [ 6464/116368]\n",
      "loss: 12.481323  [12864/116368]\n",
      "loss: 4.983024  [19264/116368]\n",
      "loss: 10.817805  [25664/116368]\n",
      "loss: 6.687391  [32064/116368]\n",
      "loss: 12.501929  [38464/116368]\n",
      "loss: 18.250662  [44864/116368]\n",
      "loss: 12.488354  [51264/116368]\n",
      "loss: 13.365376  [57664/116368]\n",
      "loss: 10.007018  [64064/116368]\n",
      "loss: 11.627927  [70464/116368]\n",
      "loss: 11.693016  [76864/116368]\n",
      "loss: 5.013101  [83264/116368]\n",
      "loss: 11.661541  [89664/116368]\n",
      "loss: 11.632788  [96064/116368]\n",
      "loss: 9.910381  [102464/116368]\n",
      "loss: 11.630584  [108864/116368]\n",
      "loss: 10.814859  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 13.295688  [   64/116368]\n",
      "loss: 15.753826  [ 6464/116368]\n",
      "loss: 11.615334  [12864/116368]\n",
      "loss: 10.829776  [19264/116368]\n",
      "loss: 13.339087  [25664/116368]\n",
      "loss: 9.170111  [32064/116368]\n",
      "loss: 14.921839  [38464/116368]\n",
      "loss: 9.228135  [44864/116368]\n",
      "loss: 11.645987  [51264/116368]\n",
      "loss: 6.657088  [57664/116368]\n",
      "loss: 9.225780  [64064/116368]\n",
      "loss: 10.796629  [70464/116368]\n",
      "loss: 11.672029  [76864/116368]\n",
      "loss: 10.824767  [83264/116368]\n",
      "loss: 9.177408  [89664/116368]\n",
      "loss: 9.137423  [96064/116368]\n",
      "loss: 13.395718  [102464/116368]\n",
      "loss: 11.698898  [108864/116368]\n",
      "loss: 11.663280  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 9.906907  [   64/116368]\n",
      "loss: 11.552933  [ 6464/116368]\n",
      "loss: 11.581106  [12864/116368]\n",
      "loss: 15.869026  [19264/116368]\n",
      "loss: 13.357428  [25664/116368]\n",
      "loss: 17.425833  [32064/116368]\n",
      "loss: 14.130335  [38464/116368]\n",
      "loss: 11.655955  [44864/116368]\n",
      "loss: 13.243712  [51264/116368]\n",
      "loss: 11.634138  [57664/116368]\n",
      "loss: 11.586918  [64064/116368]\n",
      "loss: 10.830196  [70464/116368]\n",
      "loss: 9.934383  [76864/116368]\n",
      "loss: 7.446810  [83264/116368]\n",
      "loss: 11.719204  [89664/116368]\n",
      "loss: 15.020216  [96064/116368]\n",
      "loss: 12.456507  [102464/116368]\n",
      "loss: 14.123042  [108864/116368]\n",
      "loss: 8.347175  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 14.211637  [   64/116368]\n",
      "loss: 14.919088  [ 6464/116368]\n",
      "loss: 15.025348  [12864/116368]\n",
      "loss: 14.977358  [19264/116368]\n",
      "loss: 10.875477  [25664/116368]\n",
      "loss: 13.325701  [32064/116368]\n",
      "loss: 9.128028  [38464/116368]\n",
      "loss: 12.526943  [44864/116368]\n",
      "loss: 9.126598  [51264/116368]\n",
      "loss: 15.871874  [57664/116368]\n",
      "loss: 15.910006  [64064/116368]\n",
      "loss: 10.806574  [70464/116368]\n",
      "loss: 11.584461  [76864/116368]\n",
      "loss: 13.249840  [83264/116368]\n",
      "loss: 6.680197  [89664/116368]\n",
      "loss: 9.961995  [96064/116368]\n",
      "loss: 9.172358  [102464/116368]\n",
      "loss: 6.654187  [108864/116368]\n",
      "loss: 13.225372  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 15.030090  [   64/116368]\n",
      "loss: 12.480383  [ 6464/116368]\n",
      "loss: 10.797073  [12864/116368]\n",
      "loss: 10.030475  [19264/116368]\n",
      "loss: 11.609797  [25664/116368]\n",
      "loss: 16.666660  [32064/116368]\n",
      "loss: 11.615939  [38464/116368]\n",
      "loss: 9.971517  [44864/116368]\n",
      "loss: 9.186850  [51264/116368]\n",
      "loss: 11.608250  [57664/116368]\n",
      "loss: 9.161479  [64064/116368]\n",
      "loss: 10.846453  [70464/116368]\n",
      "loss: 12.415966  [76864/116368]\n",
      "loss: 12.453388  [83264/116368]\n",
      "loss: 11.628868  [89664/116368]\n",
      "loss: 13.329218  [96064/116368]\n",
      "loss: 12.473035  [102464/116368]\n",
      "loss: 11.676549  [108864/116368]\n",
      "loss: 9.160046  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 17.470753  [   64/116368]\n",
      "loss: 5.865633  [ 6464/116368]\n",
      "loss: 8.320951  [12864/116368]\n",
      "loss: 13.279696  [19264/116368]\n",
      "loss: 12.382003  [25664/116368]\n",
      "loss: 11.676309  [32064/116368]\n",
      "loss: 12.556910  [38464/116368]\n",
      "loss: 14.927437  [44864/116368]\n",
      "loss: 12.489217  [51264/116368]\n",
      "loss: 11.647749  [57664/116368]\n",
      "loss: 14.937379  [64064/116368]\n",
      "loss: 12.484234  [70464/116368]\n",
      "loss: 11.567528  [76864/116368]\n",
      "loss: 10.829926  [83264/116368]\n",
      "loss: 14.112934  [89664/116368]\n",
      "loss: 12.508313  [96064/116368]\n",
      "loss: 8.271995  [102464/116368]\n",
      "loss: 10.806032  [108864/116368]\n",
      "loss: 9.178881  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 15.816069  [   64/116368]\n",
      "loss: 13.240939  [ 6464/116368]\n",
      "loss: 9.143520  [12864/116368]\n",
      "loss: 11.628895  [19264/116368]\n",
      "loss: 12.448677  [25664/116368]\n",
      "loss: 7.462740  [32064/116368]\n",
      "loss: 10.862350  [38464/116368]\n",
      "loss: 10.012159  [44864/116368]\n",
      "loss: 12.500787  [51264/116368]\n",
      "loss: 9.965509  [57664/116368]\n",
      "loss: 11.558368  [64064/116368]\n",
      "loss: 7.524503  [70464/116368]\n",
      "loss: 11.580459  [76864/116368]\n",
      "loss: 10.830145  [83264/116368]\n",
      "loss: 14.103737  [89664/116368]\n",
      "loss: 11.677018  [96064/116368]\n",
      "loss: 6.611797  [102464/116368]\n",
      "loss: 7.446669  [108864/116368]\n",
      "loss: 9.972371  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 14.973146  [   64/116368]\n",
      "loss: 11.693445  [ 6464/116368]\n",
      "loss: 10.827044  [12864/116368]\n",
      "loss: 12.393954  [19264/116368]\n",
      "loss: 13.322503  [25664/116368]\n",
      "loss: 11.552670  [32064/116368]\n",
      "loss: 14.093537  [38464/116368]\n",
      "loss: 6.651201  [44864/116368]\n",
      "loss: 11.588277  [51264/116368]\n",
      "loss: 10.767509  [57664/116368]\n",
      "loss: 10.771980  [64064/116368]\n",
      "loss: 9.174953  [70464/116368]\n",
      "loss: 7.478643  [76864/116368]\n",
      "loss: 9.969257  [83264/116368]\n",
      "loss: 12.469580  [89664/116368]\n",
      "loss: 12.409910  [96064/116368]\n",
      "loss: 13.244983  [102464/116368]\n",
      "loss: 10.801381  [108864/116368]\n",
      "loss: 16.547808  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 9.998916  [   64/116368]\n",
      "loss: 15.748825  [ 6464/116368]\n",
      "loss: 13.259611  [12864/116368]\n",
      "loss: 10.863255  [19264/116368]\n",
      "loss: 11.694105  [25664/116368]\n",
      "loss: 14.064245  [32064/116368]\n",
      "loss: 12.474810  [38464/116368]\n",
      "loss: 13.256248  [44864/116368]\n",
      "loss: 10.768919  [51264/116368]\n",
      "loss: 9.949070  [57664/116368]\n",
      "loss: 13.277783  [64064/116368]\n",
      "loss: 11.606359  [70464/116368]\n",
      "loss: 13.252765  [76864/116368]\n",
      "loss: 9.974931  [83264/116368]\n",
      "loss: 11.711129  [89664/116368]\n",
      "loss: 7.467643  [96064/116368]\n",
      "loss: 9.978705  [102464/116368]\n",
      "loss: 10.853637  [108864/116368]\n",
      "loss: 10.764667  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 10.010625  [   64/116368]\n",
      "loss: 9.851811  [ 6464/116368]\n",
      "loss: 10.794820  [12864/116368]\n",
      "loss: 9.980758  [19264/116368]\n",
      "loss: 9.099467  [25664/116368]\n",
      "loss: 9.949080  [32064/116368]\n",
      "loss: 11.547668  [38464/116368]\n",
      "loss: 4.969977  [44864/116368]\n",
      "loss: 9.100428  [51264/116368]\n",
      "loss: 12.481677  [57664/116368]\n",
      "loss: 17.476864  [64064/116368]\n",
      "loss: 11.607368  [70464/116368]\n",
      "loss: 16.539856  [76864/116368]\n",
      "loss: 8.256199  [83264/116368]\n",
      "loss: 12.568889  [89664/116368]\n",
      "loss: 4.153404  [96064/116368]\n",
      "loss: 11.698147  [102464/116368]\n",
      "loss: 10.848814  [108864/116368]\n",
      "loss: 13.264360  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 12.457318  [   64/116368]\n",
      "loss: 13.307438  [ 6464/116368]\n",
      "loss: 8.272616  [12864/116368]\n",
      "loss: 10.733251  [19264/116368]\n",
      "loss: 13.277804  [25664/116368]\n",
      "loss: 14.113247  [32064/116368]\n",
      "loss: 12.518120  [38464/116368]\n",
      "loss: 14.149612  [44864/116368]\n",
      "loss: 12.449108  [51264/116368]\n",
      "loss: 12.382998  [57664/116368]\n",
      "loss: 12.468477  [64064/116368]\n",
      "loss: 7.450846  [70464/116368]\n",
      "loss: 13.368162  [76864/116368]\n",
      "loss: 10.822482  [83264/116368]\n",
      "loss: 9.995687  [89664/116368]\n",
      "loss: 9.964593  [96064/116368]\n",
      "loss: 9.118889  [102464/116368]\n",
      "loss: 10.812173  [108864/116368]\n",
      "loss: 14.057151  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 11.644965  [   64/116368]\n",
      "loss: 17.559587  [ 6464/116368]\n",
      "loss: 13.275187  [12864/116368]\n",
      "loss: 11.710547  [19264/116368]\n",
      "loss: 6.705227  [25664/116368]\n",
      "loss: 10.830026  [32064/116368]\n",
      "loss: 5.803744  [38464/116368]\n",
      "loss: 8.340965  [44864/116368]\n",
      "loss: 9.945333  [51264/116368]\n",
      "loss: 9.144602  [57664/116368]\n",
      "loss: 9.995320  [64064/116368]\n",
      "loss: 11.717090  [70464/116368]\n",
      "loss: 10.863073  [76864/116368]\n",
      "loss: 9.963017  [83264/116368]\n",
      "loss: 10.005110  [89664/116368]\n",
      "loss: 14.930468  [96064/116368]\n",
      "loss: 11.628852  [102464/116368]\n",
      "loss: 8.346957  [108864/116368]\n",
      "loss: 11.636840  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 10.834055  [   64/116368]\n",
      "loss: 11.618472  [ 6464/116368]\n",
      "loss: 14.220148  [12864/116368]\n",
      "loss: 13.263546  [19264/116368]\n",
      "loss: 15.757358  [25664/116368]\n",
      "loss: 14.955957  [32064/116368]\n",
      "loss: 10.742509  [38464/116368]\n",
      "loss: 10.025608  [44864/116368]\n",
      "loss: 9.885572  [51264/116368]\n",
      "loss: 11.534577  [57664/116368]\n",
      "loss: 11.678553  [64064/116368]\n",
      "loss: 14.130078  [70464/116368]\n",
      "loss: 13.369673  [76864/116368]\n",
      "loss: 10.757266  [83264/116368]\n",
      "loss: 9.051062  [89664/116368]\n",
      "loss: 9.136919  [96064/116368]\n",
      "loss: 17.378613  [102464/116368]\n",
      "loss: 10.794982  [108864/116368]\n",
      "loss: 8.282954  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: SGD, Learning Rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 17.565920  [   64/116368]\n",
      "loss: 9.131293  [ 6464/116368]\n",
      "loss: 10.790958  [12864/116368]\n",
      "loss: 14.114303  [19264/116368]\n",
      "loss: 9.254110  [25664/116368]\n",
      "loss: 14.985379  [32064/116368]\n",
      "loss: 14.911592  [38464/116368]\n",
      "loss: 11.585865  [44864/116368]\n",
      "loss: 7.443524  [51264/116368]\n",
      "loss: 11.631461  [57664/116368]\n",
      "loss: 13.307273  [64064/116368]\n",
      "loss: 15.768600  [70464/116368]\n",
      "loss: 11.701495  [76864/116368]\n",
      "loss: 12.500693  [83264/116368]\n",
      "loss: 13.156012  [89664/116368]\n",
      "loss: 13.278830  [96064/116368]\n",
      "loss: 12.511368  [102464/116368]\n",
      "loss: 15.780968  [108864/116368]\n",
      "loss: 10.007154  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 9.975294  [   64/116368]\n",
      "loss: 9.961353  [ 6464/116368]\n",
      "loss: 11.543621  [12864/116368]\n",
      "loss: 17.584286  [19264/116368]\n",
      "loss: 9.163855  [25664/116368]\n",
      "loss: 13.333598  [32064/116368]\n",
      "loss: 17.475719  [38464/116368]\n",
      "loss: 12.436578  [44864/116368]\n",
      "loss: 15.045106  [51264/116368]\n",
      "loss: 9.117387  [57664/116368]\n",
      "loss: 11.673555  [64064/116368]\n",
      "loss: 14.974924  [70464/116368]\n",
      "loss: 10.036839  [76864/116368]\n",
      "loss: 12.363977  [83264/116368]\n",
      "loss: 10.005748  [89664/116368]\n",
      "loss: 10.822989  [96064/116368]\n",
      "loss: 13.281811  [102464/116368]\n",
      "loss: 14.104199  [108864/116368]\n",
      "loss: 11.465186  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 9.998478  [   64/116368]\n",
      "loss: 11.676155  [ 6464/116368]\n",
      "loss: 10.798097  [12864/116368]\n",
      "loss: 9.963793  [19264/116368]\n",
      "loss: 11.522752  [25664/116368]\n",
      "loss: 9.970954  [32064/116368]\n",
      "loss: 9.961911  [38464/116368]\n",
      "loss: 12.571877  [44864/116368]\n",
      "loss: 12.524387  [51264/116368]\n",
      "loss: 8.253033  [57664/116368]\n",
      "loss: 15.698970  [64064/116368]\n",
      "loss: 9.963540  [70464/116368]\n",
      "loss: 10.067183  [76864/116368]\n",
      "loss: 9.968272  [83264/116368]\n",
      "loss: 13.200214  [89664/116368]\n",
      "loss: 10.881239  [96064/116368]\n",
      "loss: 11.561184  [102464/116368]\n",
      "loss: 11.702146  [108864/116368]\n",
      "loss: 9.899078  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 6.586398  [   64/116368]\n",
      "loss: 8.396968  [ 6464/116368]\n",
      "loss: 14.953706  [12864/116368]\n",
      "loss: 14.981893  [19264/116368]\n",
      "loss: 9.194180  [25664/116368]\n",
      "loss: 10.893639  [32064/116368]\n",
      "loss: 6.653626  [38464/116368]\n",
      "loss: 7.571224  [44864/116368]\n",
      "loss: 12.482254  [51264/116368]\n",
      "loss: 18.251732  [57664/116368]\n",
      "loss: 12.491596  [64064/116368]\n",
      "loss: 9.932748  [70464/116368]\n",
      "loss: 10.816422  [76864/116368]\n",
      "loss: 12.509785  [83264/116368]\n",
      "loss: 12.416402  [89664/116368]\n",
      "loss: 11.673516  [96064/116368]\n",
      "loss: 16.523790  [102464/116368]\n",
      "loss: 12.507723  [108864/116368]\n",
      "loss: 11.647846  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 10.798064  [   64/116368]\n",
      "loss: 18.285067  [ 6464/116368]\n",
      "loss: 14.071471  [12864/116368]\n",
      "loss: 11.699847  [19264/116368]\n",
      "loss: 15.800653  [25664/116368]\n",
      "loss: 10.018474  [32064/116368]\n",
      "loss: 13.191260  [38464/116368]\n",
      "loss: 13.252511  [44864/116368]\n",
      "loss: 16.610790  [51264/116368]\n",
      "loss: 15.875192  [57664/116368]\n",
      "loss: 11.617018  [64064/116368]\n",
      "loss: 8.259459  [70464/116368]\n",
      "loss: 10.035083  [76864/116368]\n",
      "loss: 7.498203  [83264/116368]\n",
      "loss: 12.559206  [89664/116368]\n",
      "loss: 13.293826  [96064/116368]\n",
      "loss: 14.182771  [102464/116368]\n",
      "loss: 12.479867  [108864/116368]\n",
      "loss: 11.664358  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 9.132426  [   64/116368]\n",
      "loss: 13.421745  [ 6464/116368]\n",
      "loss: 13.293705  [12864/116368]\n",
      "loss: 10.773172  [19264/116368]\n",
      "loss: 13.327327  [25664/116368]\n",
      "loss: 14.145884  [32064/116368]\n",
      "loss: 12.361315  [38464/116368]\n",
      "loss: 12.540977  [44864/116368]\n",
      "loss: 10.034472  [51264/116368]\n",
      "loss: 10.790617  [57664/116368]\n",
      "loss: 14.894588  [64064/116368]\n",
      "loss: 10.013903  [70464/116368]\n",
      "loss: 9.953646  [76864/116368]\n",
      "loss: 15.763351  [83264/116368]\n",
      "loss: 8.308596  [89664/116368]\n",
      "loss: 14.148034  [96064/116368]\n",
      "loss: 10.753621  [102464/116368]\n",
      "loss: 12.543457  [108864/116368]\n",
      "loss: 14.094937  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 11.592856  [   64/116368]\n",
      "loss: 13.218229  [ 6464/116368]\n",
      "loss: 12.481194  [12864/116368]\n",
      "loss: 10.750349  [19264/116368]\n",
      "loss: 10.774214  [25664/116368]\n",
      "loss: 14.138462  [32064/116368]\n",
      "loss: 17.457222  [38464/116368]\n",
      "loss: 11.691607  [44864/116368]\n",
      "loss: 6.652957  [51264/116368]\n",
      "loss: 12.430432  [57664/116368]\n",
      "loss: 10.789293  [64064/116368]\n",
      "loss: 11.627966  [70464/116368]\n",
      "loss: 10.001714  [76864/116368]\n",
      "loss: 15.056554  [83264/116368]\n",
      "loss: 14.250236  [89664/116368]\n",
      "loss: 5.816825  [96064/116368]\n",
      "loss: 13.333538  [102464/116368]\n",
      "loss: 12.515800  [108864/116368]\n",
      "loss: 10.058625  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 6.701711  [   64/116368]\n",
      "loss: 13.231134  [ 6464/116368]\n",
      "loss: 10.859096  [12864/116368]\n",
      "loss: 9.961891  [19264/116368]\n",
      "loss: 16.653709  [25664/116368]\n",
      "loss: 5.856969  [32064/116368]\n",
      "loss: 16.672457  [38464/116368]\n",
      "loss: 11.671476  [44864/116368]\n",
      "loss: 6.661962  [51264/116368]\n",
      "loss: 18.288828  [57664/116368]\n",
      "loss: 13.238461  [64064/116368]\n",
      "loss: 15.848318  [70464/116368]\n",
      "loss: 9.996920  [76864/116368]\n",
      "loss: 6.624429  [83264/116368]\n",
      "loss: 12.414000  [89664/116368]\n",
      "loss: 9.861907  [96064/116368]\n",
      "loss: 10.021782  [102464/116368]\n",
      "loss: 14.181261  [108864/116368]\n",
      "loss: 9.977193  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 7.522434  [   64/116368]\n",
      "loss: 14.928602  [ 6464/116368]\n",
      "loss: 10.109277  [12864/116368]\n",
      "loss: 12.419163  [19264/116368]\n",
      "loss: 15.839648  [25664/116368]\n",
      "loss: 9.171494  [32064/116368]\n",
      "loss: 10.001011  [38464/116368]\n",
      "loss: 11.591052  [44864/116368]\n",
      "loss: 8.223285  [51264/116368]\n",
      "loss: 8.290095  [57664/116368]\n",
      "loss: 17.440687  [64064/116368]\n",
      "loss: 10.010900  [70464/116368]\n",
      "loss: 12.497882  [76864/116368]\n",
      "loss: 12.397134  [83264/116368]\n",
      "loss: 14.920909  [89664/116368]\n",
      "loss: 12.443819  [96064/116368]\n",
      "loss: 15.642385  [102464/116368]\n",
      "loss: 6.653256  [108864/116368]\n",
      "loss: 7.414762  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 9.141815  [   64/116368]\n",
      "loss: 7.420302  [ 6464/116368]\n",
      "loss: 7.528366  [12864/116368]\n",
      "loss: 14.108844  [19264/116368]\n",
      "loss: 13.215897  [25664/116368]\n",
      "loss: 9.886493  [32064/116368]\n",
      "loss: 12.545940  [38464/116368]\n",
      "loss: 11.609332  [44864/116368]\n",
      "loss: 11.625406  [51264/116368]\n",
      "loss: 11.596308  [57664/116368]\n",
      "loss: 9.999861  [64064/116368]\n",
      "loss: 15.788147  [70464/116368]\n",
      "loss: 12.414515  [76864/116368]\n",
      "loss: 10.736463  [83264/116368]\n",
      "loss: 16.618923  [89664/116368]\n",
      "loss: 12.400568  [96064/116368]\n",
      "loss: 11.594618  [102464/116368]\n",
      "loss: 9.946013  [108864/116368]\n",
      "loss: 14.261802  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 7.450738  [   64/116368]\n",
      "loss: 12.476847  [ 6464/116368]\n",
      "loss: 9.035625  [12864/116368]\n",
      "loss: 13.372905  [19264/116368]\n",
      "loss: 7.455507  [25664/116368]\n",
      "loss: 13.352168  [32064/116368]\n",
      "loss: 7.466308  [38464/116368]\n",
      "loss: 13.318553  [44864/116368]\n",
      "loss: 9.141661  [51264/116368]\n",
      "loss: 10.928521  [57664/116368]\n",
      "loss: 11.634418  [64064/116368]\n",
      "loss: 13.342577  [70464/116368]\n",
      "loss: 9.162532  [76864/116368]\n",
      "loss: 11.578897  [83264/116368]\n",
      "loss: 9.890870  [89664/116368]\n",
      "loss: 12.417899  [96064/116368]\n",
      "loss: 15.010067  [102464/116368]\n",
      "loss: 10.031521  [108864/116368]\n",
      "loss: 11.649964  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 8.319206  [   64/116368]\n",
      "loss: 11.650841  [ 6464/116368]\n",
      "loss: 13.345946  [12864/116368]\n",
      "loss: 9.146917  [19264/116368]\n",
      "loss: 15.703163  [25664/116368]\n",
      "loss: 9.124917  [32064/116368]\n",
      "loss: 13.341908  [38464/116368]\n",
      "loss: 9.189424  [44864/116368]\n",
      "loss: 7.447092  [51264/116368]\n",
      "loss: 10.809653  [57664/116368]\n",
      "loss: 14.115980  [64064/116368]\n",
      "loss: 14.139922  [70464/116368]\n",
      "loss: 12.474026  [76864/116368]\n",
      "loss: 9.974912  [83264/116368]\n",
      "loss: 8.288365  [89664/116368]\n",
      "loss: 14.846341  [96064/116368]\n",
      "loss: 11.679553  [102464/116368]\n",
      "loss: 10.802719  [108864/116368]\n",
      "loss: 14.239013  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 13.252268  [   64/116368]\n",
      "loss: 9.121347  [ 6464/116368]\n",
      "loss: 10.835917  [12864/116368]\n",
      "loss: 12.391514  [19264/116368]\n",
      "loss: 16.634964  [25664/116368]\n",
      "loss: 12.577553  [32064/116368]\n",
      "loss: 4.978667  [38464/116368]\n",
      "loss: 10.024534  [44864/116368]\n",
      "loss: 13.321289  [51264/116368]\n",
      "loss: 18.274273  [57664/116368]\n",
      "loss: 13.272628  [64064/116368]\n",
      "loss: 9.964046  [70464/116368]\n",
      "loss: 12.446621  [76864/116368]\n",
      "loss: 7.449328  [83264/116368]\n",
      "loss: 13.342194  [89664/116368]\n",
      "loss: 14.168051  [96064/116368]\n",
      "loss: 11.573126  [102464/116368]\n",
      "loss: 8.293463  [108864/116368]\n",
      "loss: 15.800768  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 15.908540  [   64/116368]\n",
      "loss: 9.208600  [ 6464/116368]\n",
      "loss: 12.465981  [12864/116368]\n",
      "loss: 13.415415  [19264/116368]\n",
      "loss: 16.537762  [25664/116368]\n",
      "loss: 12.567432  [32064/116368]\n",
      "loss: 13.261803  [38464/116368]\n",
      "loss: 17.440405  [44864/116368]\n",
      "loss: 9.955433  [51264/116368]\n",
      "loss: 12.385242  [57664/116368]\n",
      "loss: 6.653722  [64064/116368]\n",
      "loss: 12.507282  [70464/116368]\n",
      "loss: 7.511302  [76864/116368]\n",
      "loss: 10.765890  [83264/116368]\n",
      "loss: 10.831556  [89664/116368]\n",
      "loss: 15.040195  [96064/116368]\n",
      "loss: 9.986063  [102464/116368]\n",
      "loss: 9.166716  [108864/116368]\n",
      "loss: 10.699582  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 13.256012  [   64/116368]\n",
      "loss: 14.033699  [ 6464/116368]\n",
      "loss: 11.669772  [12864/116368]\n",
      "loss: 14.891257  [19264/116368]\n",
      "loss: 11.672970  [25664/116368]\n",
      "loss: 11.605235  [32064/116368]\n",
      "loss: 11.544047  [38464/116368]\n",
      "loss: 9.948084  [44864/116368]\n",
      "loss: 13.215176  [51264/116368]\n",
      "loss: 8.244488  [57664/116368]\n",
      "loss: 10.793203  [64064/116368]\n",
      "loss: 9.150591  [70464/116368]\n",
      "loss: 11.612738  [76864/116368]\n",
      "loss: 9.102049  [83264/116368]\n",
      "loss: 11.627688  [89664/116368]\n",
      "loss: 9.262973  [96064/116368]\n",
      "loss: 13.248573  [102464/116368]\n",
      "loss: 14.890765  [108864/116368]\n",
      "loss: 11.591076  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 9.976993  [   64/116368]\n",
      "loss: 13.342169  [ 6464/116368]\n",
      "loss: 10.836563  [12864/116368]\n",
      "loss: 14.132427  [19264/116368]\n",
      "loss: 13.269085  [25664/116368]\n",
      "loss: 11.602494  [32064/116368]\n",
      "loss: 11.579370  [38464/116368]\n",
      "loss: 10.822142  [44864/116368]\n",
      "loss: 13.315313  [51264/116368]\n",
      "loss: 15.803818  [57664/116368]\n",
      "loss: 7.468458  [64064/116368]\n",
      "loss: 9.994702  [70464/116368]\n",
      "loss: 13.300694  [76864/116368]\n",
      "loss: 11.648115  [83264/116368]\n",
      "loss: 13.300335  [89664/116368]\n",
      "loss: 8.303969  [96064/116368]\n",
      "loss: 5.828838  [102464/116368]\n",
      "loss: 8.328979  [108864/116368]\n",
      "loss: 14.816617  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 15.794481  [   64/116368]\n",
      "loss: 12.546220  [ 6464/116368]\n",
      "loss: 7.465088  [12864/116368]\n",
      "loss: 6.613827  [19264/116368]\n",
      "loss: 11.595988  [25664/116368]\n",
      "loss: 8.322228  [32064/116368]\n",
      "loss: 12.466190  [38464/116368]\n",
      "loss: 9.191193  [44864/116368]\n",
      "loss: 9.174457  [51264/116368]\n",
      "loss: 11.646976  [57664/116368]\n",
      "loss: 4.959637  [64064/116368]\n",
      "loss: 8.354095  [70464/116368]\n",
      "loss: 13.331320  [76864/116368]\n",
      "loss: 7.459701  [83264/116368]\n",
      "loss: 9.162155  [89664/116368]\n",
      "loss: 15.770185  [96064/116368]\n",
      "loss: 9.947658  [102464/116368]\n",
      "loss: 8.378529  [108864/116368]\n",
      "loss: 11.671012  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 9.948786  [   64/116368]\n",
      "loss: 12.519190  [ 6464/116368]\n",
      "loss: 11.599210  [12864/116368]\n",
      "loss: 9.994783  [19264/116368]\n",
      "loss: 12.316657  [25664/116368]\n",
      "loss: 7.474880  [32064/116368]\n",
      "loss: 9.913038  [38464/116368]\n",
      "loss: 13.330044  [44864/116368]\n",
      "loss: 11.631716  [51264/116368]\n",
      "loss: 9.154428  [57664/116368]\n",
      "loss: 15.017984  [64064/116368]\n",
      "loss: 10.854877  [70464/116368]\n",
      "loss: 10.734821  [76864/116368]\n",
      "loss: 7.513667  [83264/116368]\n",
      "loss: 13.261353  [89664/116368]\n",
      "loss: 10.829585  [96064/116368]\n",
      "loss: 14.959365  [102464/116368]\n",
      "loss: 9.993155  [108864/116368]\n",
      "loss: 14.979154  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 10.827599  [   64/116368]\n",
      "loss: 10.769430  [ 6464/116368]\n",
      "loss: 9.881371  [12864/116368]\n",
      "loss: 8.329139  [19264/116368]\n",
      "loss: 15.841665  [25664/116368]\n",
      "loss: 12.497400  [32064/116368]\n",
      "loss: 9.109802  [38464/116368]\n",
      "loss: 15.745605  [44864/116368]\n",
      "loss: 12.503789  [51264/116368]\n",
      "loss: 11.646385  [57664/116368]\n",
      "loss: 7.539590  [64064/116368]\n",
      "loss: 7.525456  [70464/116368]\n",
      "loss: 14.903987  [76864/116368]\n",
      "loss: 9.997212  [83264/116368]\n",
      "loss: 10.814944  [89664/116368]\n",
      "loss: 13.357591  [96064/116368]\n",
      "loss: 10.750716  [102464/116368]\n",
      "loss: 15.777622  [108864/116368]\n",
      "loss: 10.771484  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 6.695456  [   64/116368]\n",
      "loss: 14.911609  [ 6464/116368]\n",
      "loss: 8.380322  [12864/116368]\n",
      "loss: 7.491152  [19264/116368]\n",
      "loss: 7.488677  [25664/116368]\n",
      "loss: 18.247400  [32064/116368]\n",
      "loss: 17.509974  [38464/116368]\n",
      "loss: 7.467255  [44864/116368]\n",
      "loss: 19.071171  [51264/116368]\n",
      "loss: 7.514255  [57664/116368]\n",
      "loss: 9.944518  [64064/116368]\n",
      "loss: 10.774611  [70464/116368]\n",
      "loss: 5.834484  [76864/116368]\n",
      "loss: 9.981987  [83264/116368]\n",
      "loss: 7.569021  [89664/116368]\n",
      "loss: 11.657999  [96064/116368]\n",
      "loss: 9.096228  [102464/116368]\n",
      "loss: 14.099488  [108864/116368]\n",
      "loss: 14.952656  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: SGD, Learning Rate: 0.0005\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 12.392625  [   64/116368]\n",
      "loss: 8.333414  [ 6464/116368]\n",
      "loss: 14.153811  [12864/116368]\n",
      "loss: 10.852275  [19264/116368]\n",
      "loss: 20.779358  [25664/116368]\n",
      "loss: 13.265420  [32064/116368]\n",
      "loss: 9.143808  [38464/116368]\n",
      "loss: 14.007479  [44864/116368]\n",
      "loss: 9.984329  [51264/116368]\n",
      "loss: 17.443998  [57664/116368]\n",
      "loss: 10.829757  [64064/116368]\n",
      "loss: 13.388302  [70464/116368]\n",
      "loss: 10.864933  [76864/116368]\n",
      "loss: 10.887106  [83264/116368]\n",
      "loss: 10.752418  [89664/116368]\n",
      "loss: 17.527334  [96064/116368]\n",
      "loss: 11.615220  [102464/116368]\n",
      "loss: 11.582180  [108864/116368]\n",
      "loss: 10.851115  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 12.550650  [   64/116368]\n",
      "loss: 12.475204  [ 6464/116368]\n",
      "loss: 9.884457  [12864/116368]\n",
      "loss: 11.604456  [19264/116368]\n",
      "loss: 10.783281  [25664/116368]\n",
      "loss: 14.870195  [32064/116368]\n",
      "loss: 14.142633  [38464/116368]\n",
      "loss: 10.724670  [44864/116368]\n",
      "loss: 4.969287  [51264/116368]\n",
      "loss: 11.705094  [57664/116368]\n",
      "loss: 12.553015  [64064/116368]\n",
      "loss: 15.794156  [70464/116368]\n",
      "loss: 10.800928  [76864/116368]\n",
      "loss: 7.495789  [83264/116368]\n",
      "loss: 14.132671  [89664/116368]\n",
      "loss: 18.236153  [96064/116368]\n",
      "loss: 10.810877  [102464/116368]\n",
      "loss: 12.404476  [108864/116368]\n",
      "loss: 17.348692  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 11.646772  [   64/116368]\n",
      "loss: 13.236391  [ 6464/116368]\n",
      "loss: 9.937499  [12864/116368]\n",
      "loss: 10.848738  [19264/116368]\n",
      "loss: 13.232140  [25664/116368]\n",
      "loss: 10.791219  [32064/116368]\n",
      "loss: 10.811332  [38464/116368]\n",
      "loss: 16.610094  [44864/116368]\n",
      "loss: 10.736030  [51264/116368]\n",
      "loss: 18.277088  [57664/116368]\n",
      "loss: 10.044717  [64064/116368]\n",
      "loss: 11.617527  [70464/116368]\n",
      "loss: 9.101952  [76864/116368]\n",
      "loss: 12.407612  [83264/116368]\n",
      "loss: 9.157877  [89664/116368]\n",
      "loss: 11.722769  [96064/116368]\n",
      "loss: 8.349759  [102464/116368]\n",
      "loss: 7.492307  [108864/116368]\n",
      "loss: 13.246501  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 13.354203  [   64/116368]\n",
      "loss: 8.314679  [ 6464/116368]\n",
      "loss: 8.305040  [12864/116368]\n",
      "loss: 10.763631  [19264/116368]\n",
      "loss: 12.429961  [25664/116368]\n",
      "loss: 9.113713  [32064/116368]\n",
      "loss: 10.062302  [38464/116368]\n",
      "loss: 15.009134  [44864/116368]\n",
      "loss: 7.477831  [51264/116368]\n",
      "loss: 6.627313  [57664/116368]\n",
      "loss: 14.168052  [64064/116368]\n",
      "loss: 14.093946  [70464/116368]\n",
      "loss: 14.113487  [76864/116368]\n",
      "loss: 7.426671  [83264/116368]\n",
      "loss: 13.197908  [89664/116368]\n",
      "loss: 8.323054  [96064/116368]\n",
      "loss: 9.953489  [102464/116368]\n",
      "loss: 12.375690  [108864/116368]\n",
      "loss: 14.204488  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 10.832702  [   64/116368]\n",
      "loss: 9.951866  [ 6464/116368]\n",
      "loss: 13.206110  [12864/116368]\n",
      "loss: 6.620558  [19264/116368]\n",
      "loss: 11.581658  [25664/116368]\n",
      "loss: 14.227439  [32064/116368]\n",
      "loss: 9.139975  [38464/116368]\n",
      "loss: 14.974924  [44864/116368]\n",
      "loss: 9.158858  [51264/116368]\n",
      "loss: 11.610069  [57664/116368]\n",
      "loss: 11.687021  [64064/116368]\n",
      "loss: 9.944885  [70464/116368]\n",
      "loss: 8.346459  [76864/116368]\n",
      "loss: 11.576588  [83264/116368]\n",
      "loss: 14.933675  [89664/116368]\n",
      "loss: 10.799405  [96064/116368]\n",
      "loss: 8.307009  [102464/116368]\n",
      "loss: 7.522362  [108864/116368]\n",
      "loss: 10.733885  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.987801  [   64/116368]\n",
      "loss: 15.017853  [ 6464/116368]\n",
      "loss: 9.106760  [12864/116368]\n",
      "loss: 8.400793  [19264/116368]\n",
      "loss: 9.184675  [25664/116368]\n",
      "loss: 14.996986  [32064/116368]\n",
      "loss: 13.198830  [38464/116368]\n",
      "loss: 12.466807  [44864/116368]\n",
      "loss: 12.407925  [51264/116368]\n",
      "loss: 11.643437  [57664/116368]\n",
      "loss: 9.112088  [64064/116368]\n",
      "loss: 10.786374  [70464/116368]\n",
      "loss: 11.714767  [76864/116368]\n",
      "loss: 12.402822  [83264/116368]\n",
      "loss: 10.752964  [89664/116368]\n",
      "loss: 11.704869  [96064/116368]\n",
      "loss: 10.873920  [102464/116368]\n",
      "loss: 15.034561  [108864/116368]\n",
      "loss: 8.307670  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 9.983245  [   64/116368]\n",
      "loss: 9.979494  [ 6464/116368]\n",
      "loss: 10.929153  [12864/116368]\n",
      "loss: 12.480005  [19264/116368]\n",
      "loss: 12.505599  [25664/116368]\n",
      "loss: 11.686664  [32064/116368]\n",
      "loss: 7.445355  [38464/116368]\n",
      "loss: 7.471253  [44864/116368]\n",
      "loss: 16.736687  [51264/116368]\n",
      "loss: 14.142061  [57664/116368]\n",
      "loss: 9.197706  [64064/116368]\n",
      "loss: 9.117558  [70464/116368]\n",
      "loss: 13.283263  [76864/116368]\n",
      "loss: 15.028816  [83264/116368]\n",
      "loss: 14.020497  [89664/116368]\n",
      "loss: 6.625110  [96064/116368]\n",
      "loss: 12.509770  [102464/116368]\n",
      "loss: 15.820044  [108864/116368]\n",
      "loss: 10.027905  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 13.410534  [   64/116368]\n",
      "loss: 10.853880  [ 6464/116368]\n",
      "loss: 13.249601  [12864/116368]\n",
      "loss: 8.335287  [19264/116368]\n",
      "loss: 11.734672  [25664/116368]\n",
      "loss: 11.612107  [32064/116368]\n",
      "loss: 9.064009  [38464/116368]\n",
      "loss: 11.716997  [44864/116368]\n",
      "loss: 14.113928  [51264/116368]\n",
      "loss: 14.960538  [57664/116368]\n",
      "loss: 10.803610  [64064/116368]\n",
      "loss: 15.760052  [70464/116368]\n",
      "loss: 10.863249  [76864/116368]\n",
      "loss: 11.739149  [83264/116368]\n",
      "loss: 8.322677  [89664/116368]\n",
      "loss: 10.877482  [96064/116368]\n",
      "loss: 12.502960  [102464/116368]\n",
      "loss: 9.079157  [108864/116368]\n",
      "loss: 5.872703  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 9.951973  [   64/116368]\n",
      "loss: 9.157801  [ 6464/116368]\n",
      "loss: 14.137379  [12864/116368]\n",
      "loss: 10.789890  [19264/116368]\n",
      "loss: 10.691714  [25664/116368]\n",
      "loss: 12.455942  [32064/116368]\n",
      "loss: 7.469569  [38464/116368]\n",
      "loss: 10.772616  [44864/116368]\n",
      "loss: 10.871459  [51264/116368]\n",
      "loss: 9.091850  [57664/116368]\n",
      "loss: 10.069874  [64064/116368]\n",
      "loss: 10.738449  [70464/116368]\n",
      "loss: 15.857897  [76864/116368]\n",
      "loss: 8.313658  [83264/116368]\n",
      "loss: 11.570919  [89664/116368]\n",
      "loss: 8.224932  [96064/116368]\n",
      "loss: 8.282258  [102464/116368]\n",
      "loss: 10.820701  [108864/116368]\n",
      "loss: 10.809093  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 10.801867  [   64/116368]\n",
      "loss: 12.444953  [ 6464/116368]\n",
      "loss: 8.345431  [12864/116368]\n",
      "loss: 15.656244  [19264/116368]\n",
      "loss: 10.815041  [25664/116368]\n",
      "loss: 9.108613  [32064/116368]\n",
      "loss: 10.825052  [38464/116368]\n",
      "loss: 12.426692  [44864/116368]\n",
      "loss: 11.638402  [51264/116368]\n",
      "loss: 9.949674  [57664/116368]\n",
      "loss: 14.137333  [64064/116368]\n",
      "loss: 8.238181  [70464/116368]\n",
      "loss: 16.634054  [76864/116368]\n",
      "loss: 7.472088  [83264/116368]\n",
      "loss: 6.664771  [89664/116368]\n",
      "loss: 15.813857  [96064/116368]\n",
      "loss: 13.261089  [102464/116368]\n",
      "loss: 15.811563  [108864/116368]\n",
      "loss: 12.457130  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 14.077747  [   64/116368]\n",
      "loss: 15.804373  [ 6464/116368]\n",
      "loss: 11.642576  [12864/116368]\n",
      "loss: 13.288996  [19264/116368]\n",
      "loss: 11.667152  [25664/116368]\n",
      "loss: 11.650583  [32064/116368]\n",
      "loss: 9.953405  [38464/116368]\n",
      "loss: 12.480978  [44864/116368]\n",
      "loss: 12.531033  [51264/116368]\n",
      "loss: 14.012350  [57664/116368]\n",
      "loss: 14.080152  [64064/116368]\n",
      "loss: 10.782340  [70464/116368]\n",
      "loss: 14.991784  [76864/116368]\n",
      "loss: 15.804049  [83264/116368]\n",
      "loss: 8.305462  [89664/116368]\n",
      "loss: 7.473781  [96064/116368]\n",
      "loss: 12.490499  [102464/116368]\n",
      "loss: 13.305498  [108864/116368]\n",
      "loss: 10.760039  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 13.275860  [   64/116368]\n",
      "loss: 9.935934  [ 6464/116368]\n",
      "loss: 14.146832  [12864/116368]\n",
      "loss: 9.962116  [19264/116368]\n",
      "loss: 12.427996  [25664/116368]\n",
      "loss: 8.322383  [32064/116368]\n",
      "loss: 10.005176  [38464/116368]\n",
      "loss: 14.038458  [44864/116368]\n",
      "loss: 9.186214  [51264/116368]\n",
      "loss: 10.752460  [57664/116368]\n",
      "loss: 10.744791  [64064/116368]\n",
      "loss: 11.587502  [70464/116368]\n",
      "loss: 10.759001  [76864/116368]\n",
      "loss: 11.719634  [83264/116368]\n",
      "loss: 9.985518  [89664/116368]\n",
      "loss: 10.843809  [96064/116368]\n",
      "loss: 11.602032  [102464/116368]\n",
      "loss: 10.741763  [108864/116368]\n",
      "loss: 12.507183  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 19.195349  [   64/116368]\n",
      "loss: 8.295908  [ 6464/116368]\n",
      "loss: 8.307461  [12864/116368]\n",
      "loss: 14.130261  [19264/116368]\n",
      "loss: 10.848648  [25664/116368]\n",
      "loss: 7.536229  [32064/116368]\n",
      "loss: 9.967174  [38464/116368]\n",
      "loss: 13.365273  [44864/116368]\n",
      "loss: 13.275464  [51264/116368]\n",
      "loss: 9.180094  [57664/116368]\n",
      "loss: 6.585707  [64064/116368]\n",
      "loss: 13.310719  [70464/116368]\n",
      "loss: 8.350564  [76864/116368]\n",
      "loss: 11.681599  [83264/116368]\n",
      "loss: 10.831569  [89664/116368]\n",
      "loss: 8.394605  [96064/116368]\n",
      "loss: 13.347802  [102464/116368]\n",
      "loss: 13.343385  [108864/116368]\n",
      "loss: 8.256272  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 6.651623  [   64/116368]\n",
      "loss: 13.995690  [ 6464/116368]\n",
      "loss: 11.590303  [12864/116368]\n",
      "loss: 15.026875  [19264/116368]\n",
      "loss: 10.832820  [25664/116368]\n",
      "loss: 12.487710  [32064/116368]\n",
      "loss: 4.981219  [38464/116368]\n",
      "loss: 14.960030  [44864/116368]\n",
      "loss: 3.322618  [51264/116368]\n",
      "loss: 19.198723  [57664/116368]\n",
      "loss: 12.454447  [64064/116368]\n",
      "loss: 8.287103  [70464/116368]\n",
      "loss: 9.211903  [76864/116368]\n",
      "loss: 15.718836  [83264/116368]\n",
      "loss: 8.314185  [89664/116368]\n",
      "loss: 12.520655  [96064/116368]\n",
      "loss: 9.997709  [102464/116368]\n",
      "loss: 9.082000  [108864/116368]\n",
      "loss: 19.883894  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 12.391926  [   64/116368]\n",
      "loss: 9.971598  [ 6464/116368]\n",
      "loss: 13.320853  [12864/116368]\n",
      "loss: 7.524447  [19264/116368]\n",
      "loss: 2.522160  [25664/116368]\n",
      "loss: 13.324062  [32064/116368]\n",
      "loss: 8.256654  [38464/116368]\n",
      "loss: 9.952951  [44864/116368]\n",
      "loss: 18.327103  [51264/116368]\n",
      "loss: 10.855132  [57664/116368]\n",
      "loss: 10.809627  [64064/116368]\n",
      "loss: 8.256977  [70464/116368]\n",
      "loss: 6.654966  [76864/116368]\n",
      "loss: 13.300852  [83264/116368]\n",
      "loss: 16.625490  [89664/116368]\n",
      "loss: 11.614632  [96064/116368]\n",
      "loss: 9.955472  [102464/116368]\n",
      "loss: 15.829336  [108864/116368]\n",
      "loss: 12.530884  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 9.875057  [   64/116368]\n",
      "loss: 11.645438  [ 6464/116368]\n",
      "loss: 15.786363  [12864/116368]\n",
      "loss: 17.478796  [19264/116368]\n",
      "loss: 11.620049  [25664/116368]\n",
      "loss: 15.013384  [32064/116368]\n",
      "loss: 4.174774  [38464/116368]\n",
      "loss: 11.674625  [44864/116368]\n",
      "loss: 17.461517  [51264/116368]\n",
      "loss: 15.730238  [57664/116368]\n",
      "loss: 10.766637  [64064/116368]\n",
      "loss: 9.127457  [70464/116368]\n",
      "loss: 14.920677  [76864/116368]\n",
      "loss: 9.938811  [83264/116368]\n",
      "loss: 9.989548  [89664/116368]\n",
      "loss: 9.208347  [96064/116368]\n",
      "loss: 8.367878  [102464/116368]\n",
      "loss: 12.497667  [108864/116368]\n",
      "loss: 9.154069  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 12.527429  [   64/116368]\n",
      "loss: 10.804221  [ 6464/116368]\n",
      "loss: 10.806176  [12864/116368]\n",
      "loss: 14.083479  [19264/116368]\n",
      "loss: 14.107064  [25664/116368]\n",
      "loss: 12.455046  [32064/116368]\n",
      "loss: 15.715864  [38464/116368]\n",
      "loss: 9.926476  [44864/116368]\n",
      "loss: 9.915632  [51264/116368]\n",
      "loss: 16.615673  [57664/116368]\n",
      "loss: 9.992548  [64064/116368]\n",
      "loss: 12.499308  [70464/116368]\n",
      "loss: 9.130341  [76864/116368]\n",
      "loss: 13.353563  [83264/116368]\n",
      "loss: 12.465007  [89664/116368]\n",
      "loss: 10.796021  [96064/116368]\n",
      "loss: 12.477271  [102464/116368]\n",
      "loss: 8.339466  [108864/116368]\n",
      "loss: 9.169279  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 15.768752  [   64/116368]\n",
      "loss: 17.515532  [ 6464/116368]\n",
      "loss: 14.194843  [12864/116368]\n",
      "loss: 10.793911  [19264/116368]\n",
      "loss: 12.425179  [25664/116368]\n",
      "loss: 10.780235  [32064/116368]\n",
      "loss: 14.081831  [38464/116368]\n",
      "loss: 10.790911  [44864/116368]\n",
      "loss: 15.869976  [51264/116368]\n",
      "loss: 9.142599  [57664/116368]\n",
      "loss: 15.025723  [64064/116368]\n",
      "loss: 9.206806  [70464/116368]\n",
      "loss: 15.884774  [76864/116368]\n",
      "loss: 10.780241  [83264/116368]\n",
      "loss: 13.313097  [89664/116368]\n",
      "loss: 16.468563  [96064/116368]\n",
      "loss: 12.538199  [102464/116368]\n",
      "loss: 11.570356  [108864/116368]\n",
      "loss: 14.136991  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 12.421847  [   64/116368]\n",
      "loss: 11.540261  [ 6464/116368]\n",
      "loss: 11.578441  [12864/116368]\n",
      "loss: 19.068048  [19264/116368]\n",
      "loss: 10.069395  [25664/116368]\n",
      "loss: 14.049547  [32064/116368]\n",
      "loss: 11.665593  [38464/116368]\n",
      "loss: 9.186018  [44864/116368]\n",
      "loss: 12.468493  [51264/116368]\n",
      "loss: 12.560884  [57664/116368]\n",
      "loss: 14.995087  [64064/116368]\n",
      "loss: 13.298156  [70464/116368]\n",
      "loss: 10.743016  [76864/116368]\n",
      "loss: 3.334082  [83264/116368]\n",
      "loss: 13.270076  [89664/116368]\n",
      "loss: 5.840533  [96064/116368]\n",
      "loss: 11.627082  [102464/116368]\n",
      "loss: 9.958399  [108864/116368]\n",
      "loss: 15.802959  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 9.075538  [   64/116368]\n",
      "loss: 12.480907  [ 6464/116368]\n",
      "loss: 15.791747  [12864/116368]\n",
      "loss: 14.958588  [19264/116368]\n",
      "loss: 10.802425  [25664/116368]\n",
      "loss: 13.218534  [32064/116368]\n",
      "loss: 10.835807  [38464/116368]\n",
      "loss: 10.813138  [44864/116368]\n",
      "loss: 14.105197  [51264/116368]\n",
      "loss: 12.398070  [57664/116368]\n",
      "loss: 12.502920  [64064/116368]\n",
      "loss: 9.112331  [70464/116368]\n",
      "loss: 14.133427  [76864/116368]\n",
      "loss: 17.479918  [83264/116368]\n",
      "loss: 14.175482  [89664/116368]\n",
      "loss: 11.701310  [96064/116368]\n",
      "loss: 12.404500  [102464/116368]\n",
      "loss: 9.116341  [108864/116368]\n",
      "loss: 6.602118  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: SGD, Learning Rate: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 15.008856  [   64/116368]\n",
      "loss: 10.019240  [ 6464/116368]\n",
      "loss: 12.540527  [12864/116368]\n",
      "loss: 11.570930  [19264/116368]\n",
      "loss: 8.326937  [25664/116368]\n",
      "loss: 14.988750  [32064/116368]\n",
      "loss: 17.574110  [38464/116368]\n",
      "loss: 10.785347  [44864/116368]\n",
      "loss: 12.398805  [51264/116368]\n",
      "loss: 10.774858  [57664/116368]\n",
      "loss: 14.135100  [64064/116368]\n",
      "loss: 8.305052  [70464/116368]\n",
      "loss: 13.232258  [76864/116368]\n",
      "loss: 14.109569  [83264/116368]\n",
      "loss: 11.717566  [89664/116368]\n",
      "loss: 12.362787  [96064/116368]\n",
      "loss: 9.900247  [102464/116368]\n",
      "loss: 14.189821  [108864/116368]\n",
      "loss: 10.795475  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 15.747841  [   64/116368]\n",
      "loss: 11.687044  [ 6464/116368]\n",
      "loss: 11.596182  [12864/116368]\n",
      "loss: 8.388536  [19264/116368]\n",
      "loss: 12.510999  [25664/116368]\n",
      "loss: 10.818969  [32064/116368]\n",
      "loss: 12.474813  [38464/116368]\n",
      "loss: 9.074652  [44864/116368]\n",
      "loss: 9.985250  [51264/116368]\n",
      "loss: 10.025150  [57664/116368]\n",
      "loss: 11.599795  [64064/116368]\n",
      "loss: 9.100016  [70464/116368]\n",
      "loss: 10.837398  [76864/116368]\n",
      "loss: 14.185074  [83264/116368]\n",
      "loss: 9.965337  [89664/116368]\n",
      "loss: 9.965620  [96064/116368]\n",
      "loss: 9.889094  [102464/116368]\n",
      "loss: 14.967860  [108864/116368]\n",
      "loss: 5.813024  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 9.114460  [   64/116368]\n",
      "loss: 13.363553  [ 6464/116368]\n",
      "loss: 10.906933  [12864/116368]\n",
      "loss: 10.827332  [19264/116368]\n",
      "loss: 9.236673  [25664/116368]\n",
      "loss: 9.986928  [32064/116368]\n",
      "loss: 4.976370  [38464/116368]\n",
      "loss: 11.649256  [44864/116368]\n",
      "loss: 10.793890  [51264/116368]\n",
      "loss: 9.945097  [57664/116368]\n",
      "loss: 13.252179  [64064/116368]\n",
      "loss: 13.299822  [70464/116368]\n",
      "loss: 10.758512  [76864/116368]\n",
      "loss: 13.264594  [83264/116368]\n",
      "loss: 14.114431  [89664/116368]\n",
      "loss: 13.354348  [96064/116368]\n",
      "loss: 9.973387  [102464/116368]\n",
      "loss: 5.765002  [108864/116368]\n",
      "loss: 10.799435  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 13.330325  [   64/116368]\n",
      "loss: 13.251582  [ 6464/116368]\n",
      "loss: 10.907696  [12864/116368]\n",
      "loss: 12.400882  [19264/116368]\n",
      "loss: 9.986696  [25664/116368]\n",
      "loss: 15.013769  [32064/116368]\n",
      "loss: 11.670752  [38464/116368]\n",
      "loss: 9.991579  [44864/116368]\n",
      "loss: 4.186990  [51264/116368]\n",
      "loss: 10.741532  [57664/116368]\n",
      "loss: 9.178059  [64064/116368]\n",
      "loss: 7.564759  [70464/116368]\n",
      "loss: 14.108479  [76864/116368]\n",
      "loss: 12.434137  [83264/116368]\n",
      "loss: 14.107100  [89664/116368]\n",
      "loss: 12.396271  [96064/116368]\n",
      "loss: 9.998690  [102464/116368]\n",
      "loss: 9.147511  [108864/116368]\n",
      "loss: 14.060920  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 7.410978  [   64/116368]\n",
      "loss: 9.165890  [ 6464/116368]\n",
      "loss: 14.163711  [12864/116368]\n",
      "loss: 11.594021  [19264/116368]\n",
      "loss: 10.776592  [25664/116368]\n",
      "loss: 7.489146  [32064/116368]\n",
      "loss: 13.407615  [38464/116368]\n",
      "loss: 15.806005  [44864/116368]\n",
      "loss: 10.811779  [51264/116368]\n",
      "loss: 8.312536  [57664/116368]\n",
      "loss: 11.567219  [64064/116368]\n",
      "loss: 18.994144  [70464/116368]\n",
      "loss: 11.686152  [76864/116368]\n",
      "loss: 9.995775  [83264/116368]\n",
      "loss: 7.481268  [89664/116368]\n",
      "loss: 14.984741  [96064/116368]\n",
      "loss: 7.504832  [102464/116368]\n",
      "loss: 9.082818  [108864/116368]\n",
      "loss: 9.133072  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 14.930141  [   64/116368]\n",
      "loss: 8.258677  [ 6464/116368]\n",
      "loss: 10.878077  [12864/116368]\n",
      "loss: 11.622749  [19264/116368]\n",
      "loss: 19.863997  [25664/116368]\n",
      "loss: 14.104414  [32064/116368]\n",
      "loss: 9.986730  [38464/116368]\n",
      "loss: 11.579202  [44864/116368]\n",
      "loss: 7.420178  [51264/116368]\n",
      "loss: 18.336349  [57664/116368]\n",
      "loss: 18.246140  [64064/116368]\n",
      "loss: 5.846209  [70464/116368]\n",
      "loss: 13.299879  [76864/116368]\n",
      "loss: 7.516291  [83264/116368]\n",
      "loss: 6.635119  [89664/116368]\n",
      "loss: 11.661313  [96064/116368]\n",
      "loss: 10.031109  [102464/116368]\n",
      "loss: 8.411110  [108864/116368]\n",
      "loss: 15.750601  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 9.093822  [   64/116368]\n",
      "loss: 9.997425  [ 6464/116368]\n",
      "loss: 10.806443  [12864/116368]\n",
      "loss: 14.142213  [19264/116368]\n",
      "loss: 11.711052  [25664/116368]\n",
      "loss: 9.178843  [32064/116368]\n",
      "loss: 14.921902  [38464/116368]\n",
      "loss: 10.765924  [44864/116368]\n",
      "loss: 12.442386  [51264/116368]\n",
      "loss: 12.539200  [57664/116368]\n",
      "loss: 9.158238  [64064/116368]\n",
      "loss: 8.378710  [70464/116368]\n",
      "loss: 11.595933  [76864/116368]\n",
      "loss: 14.153288  [83264/116368]\n",
      "loss: 10.782469  [89664/116368]\n",
      "loss: 12.506540  [96064/116368]\n",
      "loss: 11.655094  [102464/116368]\n",
      "loss: 9.853837  [108864/116368]\n",
      "loss: 10.821354  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 10.034582  [   64/116368]\n",
      "loss: 14.171840  [ 6464/116368]\n",
      "loss: 14.137732  [12864/116368]\n",
      "loss: 6.639318  [19264/116368]\n",
      "loss: 9.175100  [25664/116368]\n",
      "loss: 11.606400  [32064/116368]\n",
      "loss: 12.452944  [38464/116368]\n",
      "loss: 6.606979  [44864/116368]\n",
      "loss: 12.428030  [51264/116368]\n",
      "loss: 9.138906  [57664/116368]\n",
      "loss: 13.292804  [64064/116368]\n",
      "loss: 12.569150  [70464/116368]\n",
      "loss: 5.816252  [76864/116368]\n",
      "loss: 7.417398  [83264/116368]\n",
      "loss: 7.484393  [89664/116368]\n",
      "loss: 9.974903  [96064/116368]\n",
      "loss: 9.134309  [102464/116368]\n",
      "loss: 11.608649  [108864/116368]\n",
      "loss: 11.633017  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 9.941823  [   64/116368]\n",
      "loss: 9.942994  [ 6464/116368]\n",
      "loss: 11.651240  [12864/116368]\n",
      "loss: 9.911691  [19264/116368]\n",
      "loss: 9.084261  [25664/116368]\n",
      "loss: 12.465275  [32064/116368]\n",
      "loss: 9.120091  [38464/116368]\n",
      "loss: 14.944800  [44864/116368]\n",
      "loss: 8.346409  [51264/116368]\n",
      "loss: 14.110771  [57664/116368]\n",
      "loss: 15.061399  [64064/116368]\n",
      "loss: 12.433465  [70464/116368]\n",
      "loss: 11.593467  [76864/116368]\n",
      "loss: 7.513736  [83264/116368]\n",
      "loss: 10.799734  [89664/116368]\n",
      "loss: 9.139962  [96064/116368]\n",
      "loss: 10.839949  [102464/116368]\n",
      "loss: 12.462969  [108864/116368]\n",
      "loss: 14.949364  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 16.588135  [   64/116368]\n",
      "loss: 9.952670  [ 6464/116368]\n",
      "loss: 14.096394  [12864/116368]\n",
      "loss: 13.258454  [19264/116368]\n",
      "loss: 14.170718  [25664/116368]\n",
      "loss: 10.816755  [32064/116368]\n",
      "loss: 10.803820  [38464/116368]\n",
      "loss: 8.338302  [44864/116368]\n",
      "loss: 7.454351  [51264/116368]\n",
      "loss: 9.125834  [57664/116368]\n",
      "loss: 16.661907  [64064/116368]\n",
      "loss: 8.359188  [70464/116368]\n",
      "loss: 10.814665  [76864/116368]\n",
      "loss: 5.738472  [83264/116368]\n",
      "loss: 16.595011  [89664/116368]\n",
      "loss: 14.103697  [96064/116368]\n",
      "loss: 9.149590  [102464/116368]\n",
      "loss: 13.173956  [108864/116368]\n",
      "loss: 10.820411  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 11.635341  [   64/116368]\n",
      "loss: 9.988368  [ 6464/116368]\n",
      "loss: 10.770186  [12864/116368]\n",
      "loss: 16.633299  [19264/116368]\n",
      "loss: 13.329877  [25664/116368]\n",
      "loss: 9.088164  [32064/116368]\n",
      "loss: 13.293102  [38464/116368]\n",
      "loss: 14.986932  [44864/116368]\n",
      "loss: 14.989073  [51264/116368]\n",
      "loss: 6.681729  [57664/116368]\n",
      "loss: 9.144145  [64064/116368]\n",
      "loss: 16.620316  [70464/116368]\n",
      "loss: 13.391240  [76864/116368]\n",
      "loss: 13.436895  [83264/116368]\n",
      "loss: 11.648891  [89664/116368]\n",
      "loss: 10.783777  [96064/116368]\n",
      "loss: 10.810338  [102464/116368]\n",
      "loss: 13.277404  [108864/116368]\n",
      "loss: 14.052031  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 8.343955  [   64/116368]\n",
      "loss: 15.845682  [ 6464/116368]\n",
      "loss: 6.604193  [12864/116368]\n",
      "loss: 17.298750  [19264/116368]\n",
      "loss: 12.521381  [25664/116368]\n",
      "loss: 14.123029  [32064/116368]\n",
      "loss: 9.173324  [38464/116368]\n",
      "loss: 10.062281  [44864/116368]\n",
      "loss: 7.433404  [51264/116368]\n",
      "loss: 10.798274  [57664/116368]\n",
      "loss: 9.134585  [64064/116368]\n",
      "loss: 9.136807  [70464/116368]\n",
      "loss: 10.864806  [76864/116368]\n",
      "loss: 16.488022  [83264/116368]\n",
      "loss: 10.050481  [89664/116368]\n",
      "loss: 10.842742  [96064/116368]\n",
      "loss: 8.267778  [102464/116368]\n",
      "loss: 14.965693  [108864/116368]\n",
      "loss: 13.304597  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 9.150963  [   64/116368]\n",
      "loss: 13.407600  [ 6464/116368]\n",
      "loss: 9.200268  [12864/116368]\n",
      "loss: 8.301776  [19264/116368]\n",
      "loss: 10.816735  [25664/116368]\n",
      "loss: 10.838083  [32064/116368]\n",
      "loss: 11.610207  [38464/116368]\n",
      "loss: 16.650791  [44864/116368]\n",
      "loss: 7.521057  [51264/116368]\n",
      "loss: 15.081251  [57664/116368]\n",
      "loss: 10.845167  [64064/116368]\n",
      "loss: 9.957015  [70464/116368]\n",
      "loss: 14.155774  [76864/116368]\n",
      "loss: 8.333228  [83264/116368]\n",
      "loss: 16.686367  [89664/116368]\n",
      "loss: 10.790919  [96064/116368]\n",
      "loss: 9.053808  [102464/116368]\n",
      "loss: 7.461250  [108864/116368]\n",
      "loss: 16.608648  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 10.811758  [   64/116368]\n",
      "loss: 11.595281  [ 6464/116368]\n",
      "loss: 11.646268  [12864/116368]\n",
      "loss: 12.519716  [19264/116368]\n",
      "loss: 10.038291  [25664/116368]\n",
      "loss: 11.655422  [32064/116368]\n",
      "loss: 13.228082  [38464/116368]\n",
      "loss: 6.647143  [44864/116368]\n",
      "loss: 10.793578  [51264/116368]\n",
      "loss: 11.669243  [57664/116368]\n",
      "loss: 14.982477  [64064/116368]\n",
      "loss: 15.830533  [70464/116368]\n",
      "loss: 12.407852  [76864/116368]\n",
      "loss: 11.682034  [83264/116368]\n",
      "loss: 14.119160  [89664/116368]\n",
      "loss: 15.811007  [96064/116368]\n",
      "loss: 10.835890  [102464/116368]\n",
      "loss: 13.365318  [108864/116368]\n",
      "loss: 14.930741  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 18.277828  [   64/116368]\n",
      "loss: 10.008141  [ 6464/116368]\n",
      "loss: 9.151055  [12864/116368]\n",
      "loss: 9.099993  [19264/116368]\n",
      "loss: 13.177485  [25664/116368]\n",
      "loss: 9.881650  [32064/116368]\n",
      "loss: 13.320230  [38464/116368]\n",
      "loss: 13.334774  [44864/116368]\n",
      "loss: 12.487193  [51264/116368]\n",
      "loss: 11.636955  [57664/116368]\n",
      "loss: 7.506575  [64064/116368]\n",
      "loss: 15.900812  [70464/116368]\n",
      "loss: 10.878077  [76864/116368]\n",
      "loss: 9.925268  [83264/116368]\n",
      "loss: 11.691213  [89664/116368]\n",
      "loss: 4.998921  [96064/116368]\n",
      "loss: 14.976440  [102464/116368]\n",
      "loss: 13.232699  [108864/116368]\n",
      "loss: 11.602768  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 13.306284  [   64/116368]\n",
      "loss: 11.615248  [ 6464/116368]\n",
      "loss: 10.823652  [12864/116368]\n",
      "loss: 14.963354  [19264/116368]\n",
      "loss: 8.317645  [25664/116368]\n",
      "loss: 14.984045  [32064/116368]\n",
      "loss: 17.512154  [38464/116368]\n",
      "loss: 14.068967  [44864/116368]\n",
      "loss: 8.389922  [51264/116368]\n",
      "loss: 8.311092  [57664/116368]\n",
      "loss: 12.493855  [64064/116368]\n",
      "loss: 11.626123  [70464/116368]\n",
      "loss: 18.278000  [76864/116368]\n",
      "loss: 13.290745  [83264/116368]\n",
      "loss: 13.256276  [89664/116368]\n",
      "loss: 7.517521  [96064/116368]\n",
      "loss: 10.039362  [102464/116368]\n",
      "loss: 12.515703  [108864/116368]\n",
      "loss: 9.986200  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 16.577324  [   64/116368]\n",
      "loss: 13.212529  [ 6464/116368]\n",
      "loss: 11.593462  [12864/116368]\n",
      "loss: 5.000582  [19264/116368]\n",
      "loss: 14.117006  [25664/116368]\n",
      "loss: 10.686844  [32064/116368]\n",
      "loss: 13.179995  [38464/116368]\n",
      "loss: 14.129545  [44864/116368]\n",
      "loss: 12.466679  [51264/116368]\n",
      "loss: 13.292533  [57664/116368]\n",
      "loss: 14.990813  [64064/116368]\n",
      "loss: 9.164944  [70464/116368]\n",
      "loss: 12.492397  [76864/116368]\n",
      "loss: 14.156460  [83264/116368]\n",
      "loss: 9.998270  [89664/116368]\n",
      "loss: 9.122828  [96064/116368]\n",
      "loss: 12.414234  [102464/116368]\n",
      "loss: 10.709557  [108864/116368]\n",
      "loss: 12.340748  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 6.615658  [   64/116368]\n",
      "loss: 8.276186  [ 6464/116368]\n",
      "loss: 13.285262  [12864/116368]\n",
      "loss: 11.621415  [19264/116368]\n",
      "loss: 10.849892  [25664/116368]\n",
      "loss: 11.605112  [32064/116368]\n",
      "loss: 12.465241  [38464/116368]\n",
      "loss: 10.786840  [44864/116368]\n",
      "loss: 11.654006  [51264/116368]\n",
      "loss: 12.578553  [57664/116368]\n",
      "loss: 9.187593  [64064/116368]\n",
      "loss: 12.424223  [70464/116368]\n",
      "loss: 13.284262  [76864/116368]\n",
      "loss: 6.734356  [83264/116368]\n",
      "loss: 7.492591  [89664/116368]\n",
      "loss: 8.351170  [96064/116368]\n",
      "loss: 14.986559  [102464/116368]\n",
      "loss: 11.634291  [108864/116368]\n",
      "loss: 8.271757  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 6.618561  [   64/116368]\n",
      "loss: 9.989150  [ 6464/116368]\n",
      "loss: 6.643305  [12864/116368]\n",
      "loss: 9.987479  [19264/116368]\n",
      "loss: 11.682109  [25664/116368]\n",
      "loss: 9.947800  [32064/116368]\n",
      "loss: 14.921564  [38464/116368]\n",
      "loss: 15.817885  [44864/116368]\n",
      "loss: 6.625096  [51264/116368]\n",
      "loss: 15.741343  [57664/116368]\n",
      "loss: 6.638432  [64064/116368]\n",
      "loss: 5.794841  [70464/116368]\n",
      "loss: 13.290234  [76864/116368]\n",
      "loss: 14.066933  [83264/116368]\n",
      "loss: 11.630397  [89664/116368]\n",
      "loss: 12.422771  [96064/116368]\n",
      "loss: 7.489146  [102464/116368]\n",
      "loss: 14.161440  [108864/116368]\n",
      "loss: 13.309111  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 15.015821  [   64/116368]\n",
      "loss: 11.590621  [ 6464/116368]\n",
      "loss: 12.525434  [12864/116368]\n",
      "loss: 13.266735  [19264/116368]\n",
      "loss: 19.917080  [25664/116368]\n",
      "loss: 10.005579  [32064/116368]\n",
      "loss: 12.436985  [38464/116368]\n",
      "loss: 14.945124  [44864/116368]\n",
      "loss: 12.356495  [51264/116368]\n",
      "loss: 12.399937  [57664/116368]\n",
      "loss: 11.570345  [64064/116368]\n",
      "loss: 6.686500  [70464/116368]\n",
      "loss: 10.822698  [76864/116368]\n",
      "loss: 9.983827  [83264/116368]\n",
      "loss: 15.817470  [89664/116368]\n",
      "loss: 7.488615  [96064/116368]\n",
      "loss: 14.950379  [102464/116368]\n",
      "loss: 13.252764  [108864/116368]\n",
      "loss: 10.836886  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: SGD, Learning Rate: 5e-05\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.803168  [   64/116368]\n",
      "loss: 9.965469  [ 6464/116368]\n",
      "loss: 8.307652  [12864/116368]\n",
      "loss: 13.240631  [19264/116368]\n",
      "loss: 11.774820  [25664/116368]\n",
      "loss: 12.401793  [32064/116368]\n",
      "loss: 8.358627  [38464/116368]\n",
      "loss: 15.835136  [44864/116368]\n",
      "loss: 10.762467  [51264/116368]\n",
      "loss: 12.425259  [57664/116368]\n",
      "loss: 12.579095  [64064/116368]\n",
      "loss: 14.951180  [70464/116368]\n",
      "loss: 12.447453  [76864/116368]\n",
      "loss: 9.922421  [83264/116368]\n",
      "loss: 13.320016  [89664/116368]\n",
      "loss: 16.561625  [96064/116368]\n",
      "loss: 15.670143  [102464/116368]\n",
      "loss: 12.451503  [108864/116368]\n",
      "loss: 10.841866  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 14.881105  [   64/116368]\n",
      "loss: 5.826463  [ 6464/116368]\n",
      "loss: 10.750139  [12864/116368]\n",
      "loss: 11.591990  [19264/116368]\n",
      "loss: 14.897852  [25664/116368]\n",
      "loss: 14.871313  [32064/116368]\n",
      "loss: 13.207779  [38464/116368]\n",
      "loss: 15.827788  [44864/116368]\n",
      "loss: 10.750698  [51264/116368]\n",
      "loss: 7.587840  [57664/116368]\n",
      "loss: 14.222437  [64064/116368]\n",
      "loss: 14.870737  [70464/116368]\n",
      "loss: 10.768957  [76864/116368]\n",
      "loss: 15.769914  [83264/116368]\n",
      "loss: 14.901703  [89664/116368]\n",
      "loss: 14.992849  [96064/116368]\n",
      "loss: 13.343763  [102464/116368]\n",
      "loss: 12.403001  [108864/116368]\n",
      "loss: 12.393042  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 11.662285  [   64/116368]\n",
      "loss: 13.305801  [ 6464/116368]\n",
      "loss: 11.614966  [12864/116368]\n",
      "loss: 10.024949  [19264/116368]\n",
      "loss: 10.717210  [25664/116368]\n",
      "loss: 13.326950  [32064/116368]\n",
      "loss: 9.100252  [38464/116368]\n",
      "loss: 9.947184  [44864/116368]\n",
      "loss: 12.540369  [51264/116368]\n",
      "loss: 7.511533  [57664/116368]\n",
      "loss: 9.235498  [64064/116368]\n",
      "loss: 14.127886  [70464/116368]\n",
      "loss: 10.797718  [76864/116368]\n",
      "loss: 12.427064  [83264/116368]\n",
      "loss: 9.179172  [89664/116368]\n",
      "loss: 17.530199  [96064/116368]\n",
      "loss: 13.257812  [102464/116368]\n",
      "loss: 14.076834  [108864/116368]\n",
      "loss: 12.429113  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 9.989444  [   64/116368]\n",
      "loss: 11.609300  [ 6464/116368]\n",
      "loss: 13.331919  [12864/116368]\n",
      "loss: 13.139982  [19264/116368]\n",
      "loss: 11.633979  [25664/116368]\n",
      "loss: 9.955696  [32064/116368]\n",
      "loss: 10.824967  [38464/116368]\n",
      "loss: 8.347477  [44864/116368]\n",
      "loss: 10.033603  [51264/116368]\n",
      "loss: 11.555104  [57664/116368]\n",
      "loss: 8.316931  [64064/116368]\n",
      "loss: 13.200623  [70464/116368]\n",
      "loss: 14.227472  [76864/116368]\n",
      "loss: 14.090967  [83264/116368]\n",
      "loss: 15.751141  [89664/116368]\n",
      "loss: 14.110493  [96064/116368]\n",
      "loss: 11.626859  [102464/116368]\n",
      "loss: 18.382191  [108864/116368]\n",
      "loss: 9.075892  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 15.764376  [   64/116368]\n",
      "loss: 10.813812  [ 6464/116368]\n",
      "loss: 11.597946  [12864/116368]\n",
      "loss: 10.870844  [19264/116368]\n",
      "loss: 12.483084  [25664/116368]\n",
      "loss: 10.886613  [32064/116368]\n",
      "loss: 11.642388  [38464/116368]\n",
      "loss: 7.459825  [44864/116368]\n",
      "loss: 13.241324  [51264/116368]\n",
      "loss: 14.133015  [57664/116368]\n",
      "loss: 9.976765  [64064/116368]\n",
      "loss: 9.060269  [70464/116368]\n",
      "loss: 9.217833  [76864/116368]\n",
      "loss: 9.145984  [83264/116368]\n",
      "loss: 10.823882  [89664/116368]\n",
      "loss: 9.017101  [96064/116368]\n",
      "loss: 9.900630  [102464/116368]\n",
      "loss: 11.590207  [108864/116368]\n",
      "loss: 10.792076  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 10.869061  [   64/116368]\n",
      "loss: 5.033479  [ 6464/116368]\n",
      "loss: 9.193132  [12864/116368]\n",
      "loss: 9.122904  [19264/116368]\n",
      "loss: 9.174479  [25664/116368]\n",
      "loss: 14.007658  [32064/116368]\n",
      "loss: 9.934940  [38464/116368]\n",
      "loss: 8.271444  [44864/116368]\n",
      "loss: 10.815108  [51264/116368]\n",
      "loss: 7.452609  [57664/116368]\n",
      "loss: 9.943121  [64064/116368]\n",
      "loss: 13.327413  [70464/116368]\n",
      "loss: 19.147329  [76864/116368]\n",
      "loss: 7.469029  [83264/116368]\n",
      "loss: 12.417928  [89664/116368]\n",
      "loss: 10.830976  [96064/116368]\n",
      "loss: 9.148619  [102464/116368]\n",
      "loss: 12.444891  [108864/116368]\n",
      "loss: 12.517138  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 10.741401  [   64/116368]\n",
      "loss: 13.301434  [ 6464/116368]\n",
      "loss: 10.007331  [12864/116368]\n",
      "loss: 12.372561  [19264/116368]\n",
      "loss: 12.535865  [25664/116368]\n",
      "loss: 10.818837  [32064/116368]\n",
      "loss: 10.804149  [38464/116368]\n",
      "loss: 9.145564  [44864/116368]\n",
      "loss: 11.616615  [51264/116368]\n",
      "loss: 13.297782  [57664/116368]\n",
      "loss: 10.829696  [64064/116368]\n",
      "loss: 4.979483  [70464/116368]\n",
      "loss: 8.366827  [76864/116368]\n",
      "loss: 16.645752  [83264/116368]\n",
      "loss: 14.951223  [89664/116368]\n",
      "loss: 14.115266  [96064/116368]\n",
      "loss: 14.115288  [102464/116368]\n",
      "loss: 10.848398  [108864/116368]\n",
      "loss: 14.967399  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 14.190655  [   64/116368]\n",
      "loss: 11.613359  [ 6464/116368]\n",
      "loss: 14.150400  [12864/116368]\n",
      "loss: 14.973756  [19264/116368]\n",
      "loss: 14.097353  [25664/116368]\n",
      "loss: 12.504869  [32064/116368]\n",
      "loss: 7.464732  [38464/116368]\n",
      "loss: 11.684118  [44864/116368]\n",
      "loss: 17.465054  [51264/116368]\n",
      "loss: 7.474185  [57664/116368]\n",
      "loss: 15.020525  [64064/116368]\n",
      "loss: 10.713277  [70464/116368]\n",
      "loss: 10.011840  [76864/116368]\n",
      "loss: 10.027672  [83264/116368]\n",
      "loss: 14.914271  [89664/116368]\n",
      "loss: 11.604607  [96064/116368]\n",
      "loss: 13.283360  [102464/116368]\n",
      "loss: 15.863687  [108864/116368]\n",
      "loss: 13.377840  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 13.276179  [   64/116368]\n",
      "loss: 7.458549  [ 6464/116368]\n",
      "loss: 8.277567  [12864/116368]\n",
      "loss: 12.424458  [19264/116368]\n",
      "loss: 10.873156  [25664/116368]\n",
      "loss: 13.310305  [32064/116368]\n",
      "loss: 14.097139  [38464/116368]\n",
      "loss: 11.646330  [44864/116368]\n",
      "loss: 15.741433  [51264/116368]\n",
      "loss: 10.831355  [57664/116368]\n",
      "loss: 14.965279  [64064/116368]\n",
      "loss: 15.876264  [70464/116368]\n",
      "loss: 6.681614  [76864/116368]\n",
      "loss: 10.745910  [83264/116368]\n",
      "loss: 13.329818  [89664/116368]\n",
      "loss: 9.983561  [96064/116368]\n",
      "loss: 14.151358  [102464/116368]\n",
      "loss: 8.325686  [108864/116368]\n",
      "loss: 14.113963  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 8.297157  [   64/116368]\n",
      "loss: 14.886643  [ 6464/116368]\n",
      "loss: 12.410204  [12864/116368]\n",
      "loss: 11.575397  [19264/116368]\n",
      "loss: 9.206013  [25664/116368]\n",
      "loss: 13.265014  [32064/116368]\n",
      "loss: 9.225410  [38464/116368]\n",
      "loss: 7.409023  [44864/116368]\n",
      "loss: 14.141848  [51264/116368]\n",
      "loss: 14.102076  [57664/116368]\n",
      "loss: 12.430331  [64064/116368]\n",
      "loss: 12.378599  [70464/116368]\n",
      "loss: 9.985350  [76864/116368]\n",
      "loss: 14.138340  [83264/116368]\n",
      "loss: 15.796112  [89664/116368]\n",
      "loss: 8.282145  [96064/116368]\n",
      "loss: 16.662868  [102464/116368]\n",
      "loss: 14.076345  [108864/116368]\n",
      "loss: 10.811251  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 9.185016  [   64/116368]\n",
      "loss: 9.942585  [ 6464/116368]\n",
      "loss: 7.493511  [12864/116368]\n",
      "loss: 9.119256  [19264/116368]\n",
      "loss: 13.226292  [25664/116368]\n",
      "loss: 6.668536  [32064/116368]\n",
      "loss: 11.593782  [38464/116368]\n",
      "loss: 8.308262  [44864/116368]\n",
      "loss: 14.932152  [51264/116368]\n",
      "loss: 13.201904  [57664/116368]\n",
      "loss: 8.284871  [64064/116368]\n",
      "loss: 7.542334  [70464/116368]\n",
      "loss: 14.939492  [76864/116368]\n",
      "loss: 11.630478  [83264/116368]\n",
      "loss: 14.090501  [89664/116368]\n",
      "loss: 12.490666  [96064/116368]\n",
      "loss: 10.016886  [102464/116368]\n",
      "loss: 17.452374  [108864/116368]\n",
      "loss: 10.893500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 12.502939  [   64/116368]\n",
      "loss: 12.481482  [ 6464/116368]\n",
      "loss: 17.541286  [12864/116368]\n",
      "loss: 16.645813  [19264/116368]\n",
      "loss: 9.956079  [25664/116368]\n",
      "loss: 10.085389  [32064/116368]\n",
      "loss: 10.819129  [38464/116368]\n",
      "loss: 7.501325  [44864/116368]\n",
      "loss: 16.587362  [51264/116368]\n",
      "loss: 9.908398  [57664/116368]\n",
      "loss: 13.326656  [64064/116368]\n",
      "loss: 11.696062  [70464/116368]\n",
      "loss: 13.254759  [76864/116368]\n",
      "loss: 9.955528  [83264/116368]\n",
      "loss: 11.679531  [89664/116368]\n",
      "loss: 11.690186  [96064/116368]\n",
      "loss: 11.617937  [102464/116368]\n",
      "loss: 16.721352  [108864/116368]\n",
      "loss: 15.868134  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 18.325668  [   64/116368]\n",
      "loss: 13.306234  [ 6464/116368]\n",
      "loss: 10.786075  [12864/116368]\n",
      "loss: 13.413577  [19264/116368]\n",
      "loss: 12.449557  [25664/116368]\n",
      "loss: 9.129871  [32064/116368]\n",
      "loss: 12.491991  [38464/116368]\n",
      "loss: 8.309579  [44864/116368]\n",
      "loss: 11.601683  [51264/116368]\n",
      "loss: 9.161604  [57664/116368]\n",
      "loss: 13.304650  [64064/116368]\n",
      "loss: 6.666445  [70464/116368]\n",
      "loss: 14.149664  [76864/116368]\n",
      "loss: 9.112971  [83264/116368]\n",
      "loss: 11.692905  [89664/116368]\n",
      "loss: 14.116793  [96064/116368]\n",
      "loss: 12.547920  [102464/116368]\n",
      "loss: 11.587816  [108864/116368]\n",
      "loss: 11.672647  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 9.134858  [   64/116368]\n",
      "loss: 8.373577  [ 6464/116368]\n",
      "loss: 10.799457  [12864/116368]\n",
      "loss: 6.596489  [19264/116368]\n",
      "loss: 14.146105  [25664/116368]\n",
      "loss: 12.451386  [32064/116368]\n",
      "loss: 14.040769  [38464/116368]\n",
      "loss: 12.384226  [44864/116368]\n",
      "loss: 7.454575  [51264/116368]\n",
      "loss: 13.322111  [57664/116368]\n",
      "loss: 11.642757  [64064/116368]\n",
      "loss: 12.539579  [70464/116368]\n",
      "loss: 12.413757  [76864/116368]\n",
      "loss: 10.738402  [83264/116368]\n",
      "loss: 11.692924  [89664/116368]\n",
      "loss: 11.607390  [96064/116368]\n",
      "loss: 8.312163  [102464/116368]\n",
      "loss: 14.847059  [108864/116368]\n",
      "loss: 11.729259  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 9.897346  [   64/116368]\n",
      "loss: 15.742416  [ 6464/116368]\n",
      "loss: 10.868752  [12864/116368]\n",
      "loss: 13.426696  [19264/116368]\n",
      "loss: 15.025757  [25664/116368]\n",
      "loss: 8.338884  [32064/116368]\n",
      "loss: 15.784878  [38464/116368]\n",
      "loss: 14.109243  [44864/116368]\n",
      "loss: 9.863938  [51264/116368]\n",
      "loss: 9.106718  [57664/116368]\n",
      "loss: 10.801825  [64064/116368]\n",
      "loss: 6.687157  [70464/116368]\n",
      "loss: 9.935551  [76864/116368]\n",
      "loss: 14.121570  [83264/116368]\n",
      "loss: 10.797903  [89664/116368]\n",
      "loss: 13.173681  [96064/116368]\n",
      "loss: 15.038404  [102464/116368]\n",
      "loss: 16.652964  [108864/116368]\n",
      "loss: 11.607058  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 11.670950  [   64/116368]\n",
      "loss: 11.645845  [ 6464/116368]\n",
      "loss: 10.023698  [12864/116368]\n",
      "loss: 14.942533  [19264/116368]\n",
      "loss: 11.704642  [25664/116368]\n",
      "loss: 7.485949  [32064/116368]\n",
      "loss: 9.159049  [38464/116368]\n",
      "loss: 8.254300  [44864/116368]\n",
      "loss: 13.287720  [51264/116368]\n",
      "loss: 15.003722  [57664/116368]\n",
      "loss: 7.478298  [64064/116368]\n",
      "loss: 10.033062  [70464/116368]\n",
      "loss: 10.781736  [76864/116368]\n",
      "loss: 12.478083  [83264/116368]\n",
      "loss: 9.164043  [89664/116368]\n",
      "loss: 12.447457  [96064/116368]\n",
      "loss: 14.918781  [102464/116368]\n",
      "loss: 11.605249  [108864/116368]\n",
      "loss: 13.343059  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 16.509047  [   64/116368]\n",
      "loss: 12.412733  [ 6464/116368]\n",
      "loss: 11.590350  [12864/116368]\n",
      "loss: 10.836828  [19264/116368]\n",
      "loss: 12.466154  [25664/116368]\n",
      "loss: 7.455318  [32064/116368]\n",
      "loss: 8.302523  [38464/116368]\n",
      "loss: 16.658625  [44864/116368]\n",
      "loss: 9.082287  [51264/116368]\n",
      "loss: 16.589588  [57664/116368]\n",
      "loss: 12.387159  [64064/116368]\n",
      "loss: 15.858868  [70464/116368]\n",
      "loss: 7.422028  [76864/116368]\n",
      "loss: 11.595964  [83264/116368]\n",
      "loss: 14.190235  [89664/116368]\n",
      "loss: 9.132917  [96064/116368]\n",
      "loss: 15.837199  [102464/116368]\n",
      "loss: 10.717514  [108864/116368]\n",
      "loss: 10.810305  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 9.969301  [   64/116368]\n",
      "loss: 5.839897  [ 6464/116368]\n",
      "loss: 11.653797  [12864/116368]\n",
      "loss: 9.183805  [19264/116368]\n",
      "loss: 12.457681  [25664/116368]\n",
      "loss: 10.829845  [32064/116368]\n",
      "loss: 8.278789  [38464/116368]\n",
      "loss: 16.666428  [44864/116368]\n",
      "loss: 9.909951  [51264/116368]\n",
      "loss: 13.393524  [57664/116368]\n",
      "loss: 11.592690  [64064/116368]\n",
      "loss: 10.796481  [70464/116368]\n",
      "loss: 7.489470  [76864/116368]\n",
      "loss: 12.500904  [83264/116368]\n",
      "loss: 9.975939  [89664/116368]\n",
      "loss: 14.241475  [96064/116368]\n",
      "loss: 12.399675  [102464/116368]\n",
      "loss: 13.322312  [108864/116368]\n",
      "loss: 14.105616  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 8.324054  [   64/116368]\n",
      "loss: 15.763429  [ 6464/116368]\n",
      "loss: 14.924261  [12864/116368]\n",
      "loss: 4.969923  [19264/116368]\n",
      "loss: 9.230535  [25664/116368]\n",
      "loss: 10.868101  [32064/116368]\n",
      "loss: 16.679352  [38464/116368]\n",
      "loss: 4.979526  [44864/116368]\n",
      "loss: 10.840319  [51264/116368]\n",
      "loss: 10.003143  [57664/116368]\n",
      "loss: 14.928892  [64064/116368]\n",
      "loss: 9.995413  [70464/116368]\n",
      "loss: 4.144933  [76864/116368]\n",
      "loss: 10.104227  [83264/116368]\n",
      "loss: 7.513661  [89664/116368]\n",
      "loss: 15.733960  [96064/116368]\n",
      "loss: 6.681981  [102464/116368]\n",
      "loss: 15.798095  [108864/116368]\n",
      "loss: 16.576916  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 12.493311  [   64/116368]\n",
      "loss: 14.937782  [ 6464/116368]\n",
      "loss: 18.314194  [12864/116368]\n",
      "loss: 10.765338  [19264/116368]\n",
      "loss: 11.640011  [25664/116368]\n",
      "loss: 13.244822  [32064/116368]\n",
      "loss: 10.776314  [38464/116368]\n",
      "loss: 14.099222  [44864/116368]\n",
      "loss: 15.772539  [51264/116368]\n",
      "loss: 12.539445  [57664/116368]\n",
      "loss: 10.801873  [64064/116368]\n",
      "loss: 16.515306  [70464/116368]\n",
      "loss: 12.526588  [76864/116368]\n",
      "loss: 7.559157  [83264/116368]\n",
      "loss: 11.666336  [89664/116368]\n",
      "loss: 6.625954  [96064/116368]\n",
      "loss: 9.180866  [102464/116368]\n",
      "loss: 10.877050  [108864/116368]\n",
      "loss: 10.007234  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: SGD, Learning Rate: 1e-05\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 12.508615  [   64/116368]\n",
      "loss: 13.221085  [ 6464/116368]\n",
      "loss: 13.333632  [12864/116368]\n",
      "loss: 12.500507  [19264/116368]\n",
      "loss: 12.493606  [25664/116368]\n",
      "loss: 12.494083  [32064/116368]\n",
      "loss: 11.688909  [38464/116368]\n",
      "loss: 10.731085  [44864/116368]\n",
      "loss: 13.309402  [51264/116368]\n",
      "loss: 9.944063  [57664/116368]\n",
      "loss: 14.154524  [64064/116368]\n",
      "loss: 11.726227  [70464/116368]\n",
      "loss: 17.470493  [76864/116368]\n",
      "loss: 16.713924  [83264/116368]\n",
      "loss: 9.147875  [89664/116368]\n",
      "loss: 9.979921  [96064/116368]\n",
      "loss: 8.340481  [102464/116368]\n",
      "loss: 17.436724  [108864/116368]\n",
      "loss: 5.788978  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 6.642165  [   64/116368]\n",
      "loss: 9.075319  [ 6464/116368]\n",
      "loss: 12.530537  [12864/116368]\n",
      "loss: 14.145493  [19264/116368]\n",
      "loss: 9.103006  [25664/116368]\n",
      "loss: 13.352498  [32064/116368]\n",
      "loss: 12.576090  [38464/116368]\n",
      "loss: 11.602398  [44864/116368]\n",
      "loss: 10.757837  [51264/116368]\n",
      "loss: 12.479160  [57664/116368]\n",
      "loss: 14.996213  [64064/116368]\n",
      "loss: 13.285138  [70464/116368]\n",
      "loss: 15.731325  [76864/116368]\n",
      "loss: 8.337780  [83264/116368]\n",
      "loss: 9.166021  [89664/116368]\n",
      "loss: 13.332478  [96064/116368]\n",
      "loss: 9.173122  [102464/116368]\n",
      "loss: 14.818075  [108864/116368]\n",
      "loss: 7.491522  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 10.826449  [   64/116368]\n",
      "loss: 9.978306  [ 6464/116368]\n",
      "loss: 9.165903  [12864/116368]\n",
      "loss: 13.316523  [19264/116368]\n",
      "loss: 9.116887  [25664/116368]\n",
      "loss: 8.308283  [32064/116368]\n",
      "loss: 10.809750  [38464/116368]\n",
      "loss: 13.268261  [44864/116368]\n",
      "loss: 18.312065  [51264/116368]\n",
      "loss: 10.743116  [57664/116368]\n",
      "loss: 15.874354  [64064/116368]\n",
      "loss: 14.048889  [70464/116368]\n",
      "loss: 14.173043  [76864/116368]\n",
      "loss: 9.982989  [83264/116368]\n",
      "loss: 10.838519  [89664/116368]\n",
      "loss: 9.955852  [96064/116368]\n",
      "loss: 11.739497  [102464/116368]\n",
      "loss: 14.136956  [108864/116368]\n",
      "loss: 14.907047  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 9.959782  [   64/116368]\n",
      "loss: 12.462132  [ 6464/116368]\n",
      "loss: 10.044027  [12864/116368]\n",
      "loss: 12.419538  [19264/116368]\n",
      "loss: 13.964588  [25664/116368]\n",
      "loss: 10.029392  [32064/116368]\n",
      "loss: 10.859911  [38464/116368]\n",
      "loss: 8.392464  [44864/116368]\n",
      "loss: 14.149788  [51264/116368]\n",
      "loss: 11.661023  [57664/116368]\n",
      "loss: 10.823799  [64064/116368]\n",
      "loss: 10.077728  [70464/116368]\n",
      "loss: 14.055832  [76864/116368]\n",
      "loss: 13.420990  [83264/116368]\n",
      "loss: 13.265759  [89664/116368]\n",
      "loss: 9.173707  [96064/116368]\n",
      "loss: 13.387274  [102464/116368]\n",
      "loss: 9.891191  [108864/116368]\n",
      "loss: 10.803439  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 9.149598  [   64/116368]\n",
      "loss: 9.097212  [ 6464/116368]\n",
      "loss: 12.500631  [12864/116368]\n",
      "loss: 9.149205  [19264/116368]\n",
      "loss: 11.662672  [25664/116368]\n",
      "loss: 11.699471  [32064/116368]\n",
      "loss: 10.792998  [38464/116368]\n",
      "loss: 14.892853  [44864/116368]\n",
      "loss: 13.351644  [51264/116368]\n",
      "loss: 12.459589  [57664/116368]\n",
      "loss: 7.473158  [64064/116368]\n",
      "loss: 10.768816  [70464/116368]\n",
      "loss: 9.199151  [76864/116368]\n",
      "loss: 11.593803  [83264/116368]\n",
      "loss: 14.092070  [89664/116368]\n",
      "loss: 14.088282  [96064/116368]\n",
      "loss: 14.914828  [102464/116368]\n",
      "loss: 16.566328  [108864/116368]\n",
      "loss: 9.984507  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 7.465522  [   64/116368]\n",
      "loss: 11.568183  [ 6464/116368]\n",
      "loss: 9.996753  [12864/116368]\n",
      "loss: 11.564675  [19264/116368]\n",
      "loss: 12.489307  [25664/116368]\n",
      "loss: 10.856540  [32064/116368]\n",
      "loss: 5.824404  [38464/116368]\n",
      "loss: 6.771419  [44864/116368]\n",
      "loss: 13.266759  [51264/116368]\n",
      "loss: 11.596281  [57664/116368]\n",
      "loss: 10.797352  [64064/116368]\n",
      "loss: 8.340002  [70464/116368]\n",
      "loss: 9.088770  [76864/116368]\n",
      "loss: 10.044299  [83264/116368]\n",
      "loss: 12.468712  [89664/116368]\n",
      "loss: 13.269207  [96064/116368]\n",
      "loss: 6.668732  [102464/116368]\n",
      "loss: 10.837633  [108864/116368]\n",
      "loss: 10.790563  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 10.789589  [   64/116368]\n",
      "loss: 17.415609  [ 6464/116368]\n",
      "loss: 13.244081  [12864/116368]\n",
      "loss: 11.648396  [19264/116368]\n",
      "loss: 12.476459  [25664/116368]\n",
      "loss: 13.297256  [32064/116368]\n",
      "loss: 14.039676  [38464/116368]\n",
      "loss: 4.937223  [44864/116368]\n",
      "loss: 15.825205  [51264/116368]\n",
      "loss: 11.645349  [57664/116368]\n",
      "loss: 14.085536  [64064/116368]\n",
      "loss: 10.872931  [70464/116368]\n",
      "loss: 15.785969  [76864/116368]\n",
      "loss: 14.148509  [83264/116368]\n",
      "loss: 14.109241  [89664/116368]\n",
      "loss: 13.285396  [96064/116368]\n",
      "loss: 11.616673  [102464/116368]\n",
      "loss: 12.495676  [108864/116368]\n",
      "loss: 11.527184  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 13.991731  [   64/116368]\n",
      "loss: 11.624457  [ 6464/116368]\n",
      "loss: 12.472975  [12864/116368]\n",
      "loss: 12.558118  [19264/116368]\n",
      "loss: 16.615555  [25664/116368]\n",
      "loss: 11.591051  [32064/116368]\n",
      "loss: 13.336004  [38464/116368]\n",
      "loss: 13.312391  [44864/116368]\n",
      "loss: 14.118958  [51264/116368]\n",
      "loss: 7.532790  [57664/116368]\n",
      "loss: 10.763619  [64064/116368]\n",
      "loss: 15.789870  [70464/116368]\n",
      "loss: 9.152203  [76864/116368]\n",
      "loss: 13.342510  [83264/116368]\n",
      "loss: 9.195108  [89664/116368]\n",
      "loss: 6.621188  [96064/116368]\n",
      "loss: 11.593477  [102464/116368]\n",
      "loss: 13.298073  [108864/116368]\n",
      "loss: 10.802388  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 13.217244  [   64/116368]\n",
      "loss: 9.150528  [ 6464/116368]\n",
      "loss: 15.813452  [12864/116368]\n",
      "loss: 13.287219  [19264/116368]\n",
      "loss: 8.282763  [25664/116368]\n",
      "loss: 9.179193  [32064/116368]\n",
      "loss: 5.791660  [38464/116368]\n",
      "loss: 13.212569  [44864/116368]\n",
      "loss: 9.923906  [51264/116368]\n",
      "loss: 10.011385  [57664/116368]\n",
      "loss: 14.165617  [64064/116368]\n",
      "loss: 12.544138  [70464/116368]\n",
      "loss: 13.300482  [76864/116368]\n",
      "loss: 10.858729  [83264/116368]\n",
      "loss: 14.883640  [89664/116368]\n",
      "loss: 10.840299  [96064/116368]\n",
      "loss: 15.809330  [102464/116368]\n",
      "loss: 14.091857  [108864/116368]\n",
      "loss: 11.603876  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 13.380247  [   64/116368]\n",
      "loss: 11.575622  [ 6464/116368]\n",
      "loss: 9.984566  [12864/116368]\n",
      "loss: 7.500789  [19264/116368]\n",
      "loss: 8.341198  [25664/116368]\n",
      "loss: 9.146927  [32064/116368]\n",
      "loss: 11.697995  [38464/116368]\n",
      "loss: 9.141184  [44864/116368]\n",
      "loss: 9.142920  [51264/116368]\n",
      "loss: 9.136100  [57664/116368]\n",
      "loss: 10.002419  [64064/116368]\n",
      "loss: 5.798675  [70464/116368]\n",
      "loss: 8.287872  [76864/116368]\n",
      "loss: 14.157524  [83264/116368]\n",
      "loss: 11.650322  [89664/116368]\n",
      "loss: 14.957147  [96064/116368]\n",
      "loss: 12.479825  [102464/116368]\n",
      "loss: 16.526302  [108864/116368]\n",
      "loss: 11.632627  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 13.377448  [   64/116368]\n",
      "loss: 15.038205  [ 6464/116368]\n",
      "loss: 12.442450  [12864/116368]\n",
      "loss: 7.500295  [19264/116368]\n",
      "loss: 10.767637  [25664/116368]\n",
      "loss: 10.816168  [32064/116368]\n",
      "loss: 10.937448  [38464/116368]\n",
      "loss: 5.805632  [44864/116368]\n",
      "loss: 10.845527  [51264/116368]\n",
      "loss: 9.158763  [57664/116368]\n",
      "loss: 10.771908  [64064/116368]\n",
      "loss: 6.695954  [70464/116368]\n",
      "loss: 14.161020  [76864/116368]\n",
      "loss: 10.854378  [83264/116368]\n",
      "loss: 10.847299  [89664/116368]\n",
      "loss: 13.222555  [96064/116368]\n",
      "loss: 10.024772  [102464/116368]\n",
      "loss: 12.364002  [108864/116368]\n",
      "loss: 8.310660  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 13.296370  [   64/116368]\n",
      "loss: 9.965588  [ 6464/116368]\n",
      "loss: 10.790916  [12864/116368]\n",
      "loss: 19.189571  [19264/116368]\n",
      "loss: 12.482009  [25664/116368]\n",
      "loss: 9.927062  [32064/116368]\n",
      "loss: 15.793641  [38464/116368]\n",
      "loss: 13.329252  [44864/116368]\n",
      "loss: 12.512938  [51264/116368]\n",
      "loss: 16.622866  [57664/116368]\n",
      "loss: 14.109457  [64064/116368]\n",
      "loss: 10.876901  [70464/116368]\n",
      "loss: 14.118612  [76864/116368]\n",
      "loss: 8.304695  [83264/116368]\n",
      "loss: 12.442968  [89664/116368]\n",
      "loss: 13.303644  [96064/116368]\n",
      "loss: 9.156646  [102464/116368]\n",
      "loss: 15.816845  [108864/116368]\n",
      "loss: 7.422427  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 12.448379  [   64/116368]\n",
      "loss: 11.623236  [ 6464/116368]\n",
      "loss: 12.413145  [12864/116368]\n",
      "loss: 15.817247  [19264/116368]\n",
      "loss: 14.994733  [25664/116368]\n",
      "loss: 12.484160  [32064/116368]\n",
      "loss: 11.628405  [38464/116368]\n",
      "loss: 12.557861  [44864/116368]\n",
      "loss: 8.282076  [51264/116368]\n",
      "loss: 13.340865  [57664/116368]\n",
      "loss: 11.611742  [64064/116368]\n",
      "loss: 6.613817  [70464/116368]\n",
      "loss: 16.619099  [76864/116368]\n",
      "loss: 13.304442  [83264/116368]\n",
      "loss: 11.635692  [89664/116368]\n",
      "loss: 15.777617  [96064/116368]\n",
      "loss: 10.877130  [102464/116368]\n",
      "loss: 11.632260  [108864/116368]\n",
      "loss: 9.901943  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 11.633820  [   64/116368]\n",
      "loss: 12.453285  [ 6464/116368]\n",
      "loss: 9.967300  [12864/116368]\n",
      "loss: 13.344490  [19264/116368]\n",
      "loss: 10.769662  [25664/116368]\n",
      "loss: 12.505041  [32064/116368]\n",
      "loss: 14.882528  [38464/116368]\n",
      "loss: 12.565982  [44864/116368]\n",
      "loss: 9.184738  [51264/116368]\n",
      "loss: 15.052537  [57664/116368]\n",
      "loss: 15.801156  [64064/116368]\n",
      "loss: 7.483201  [70464/116368]\n",
      "loss: 15.835684  [76864/116368]\n",
      "loss: 19.103010  [83264/116368]\n",
      "loss: 15.156585  [89664/116368]\n",
      "loss: 14.070647  [96064/116368]\n",
      "loss: 10.807125  [102464/116368]\n",
      "loss: 9.963070  [108864/116368]\n",
      "loss: 15.040847  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 9.987297  [   64/116368]\n",
      "loss: 15.822777  [ 6464/116368]\n",
      "loss: 9.220899  [12864/116368]\n",
      "loss: 14.194099  [19264/116368]\n",
      "loss: 9.914705  [25664/116368]\n",
      "loss: 17.401386  [32064/116368]\n",
      "loss: 11.594244  [38464/116368]\n",
      "loss: 11.610339  [44864/116368]\n",
      "loss: 4.960864  [51264/116368]\n",
      "loss: 9.896032  [57664/116368]\n",
      "loss: 12.435083  [64064/116368]\n",
      "loss: 12.404140  [70464/116368]\n",
      "loss: 14.105144  [76864/116368]\n",
      "loss: 9.096932  [83264/116368]\n",
      "loss: 9.988223  [89664/116368]\n",
      "loss: 10.002298  [96064/116368]\n",
      "loss: 8.212427  [102464/116368]\n",
      "loss: 5.801621  [108864/116368]\n",
      "loss: 14.124188  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 7.501221  [   64/116368]\n",
      "loss: 14.025103  [ 6464/116368]\n",
      "loss: 9.928011  [12864/116368]\n",
      "loss: 14.067165  [19264/116368]\n",
      "loss: 9.923477  [25664/116368]\n",
      "loss: 11.655458  [32064/116368]\n",
      "loss: 9.078730  [38464/116368]\n",
      "loss: 11.632241  [44864/116368]\n",
      "loss: 16.687492  [51264/116368]\n",
      "loss: 12.427490  [57664/116368]\n",
      "loss: 13.239182  [64064/116368]\n",
      "loss: 9.970515  [70464/116368]\n",
      "loss: 9.914575  [76864/116368]\n",
      "loss: 9.839068  [83264/116368]\n",
      "loss: 15.888882  [89664/116368]\n",
      "loss: 15.788718  [96064/116368]\n",
      "loss: 14.953444  [102464/116368]\n",
      "loss: 14.245804  [108864/116368]\n",
      "loss: 6.639349  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 12.470007  [   64/116368]\n",
      "loss: 12.451056  [ 6464/116368]\n",
      "loss: 11.647936  [12864/116368]\n",
      "loss: 13.342581  [19264/116368]\n",
      "loss: 11.635655  [25664/116368]\n",
      "loss: 13.248829  [32064/116368]\n",
      "loss: 5.797125  [38464/116368]\n",
      "loss: 19.986507  [44864/116368]\n",
      "loss: 11.551977  [51264/116368]\n",
      "loss: 9.079741  [57664/116368]\n",
      "loss: 9.166677  [64064/116368]\n",
      "loss: 10.796502  [70464/116368]\n",
      "loss: 9.977272  [76864/116368]\n",
      "loss: 12.508082  [83264/116368]\n",
      "loss: 14.034252  [89664/116368]\n",
      "loss: 13.317603  [96064/116368]\n",
      "loss: 12.479203  [102464/116368]\n",
      "loss: 14.048002  [108864/116368]\n",
      "loss: 10.860936  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 4.152010  [   64/116368]\n",
      "loss: 10.759489  [ 6464/116368]\n",
      "loss: 13.232829  [12864/116368]\n",
      "loss: 11.626820  [19264/116368]\n",
      "loss: 10.037910  [25664/116368]\n",
      "loss: 14.992503  [32064/116368]\n",
      "loss: 13.328788  [38464/116368]\n",
      "loss: 15.813747  [44864/116368]\n",
      "loss: 11.643124  [51264/116368]\n",
      "loss: 7.437376  [57664/116368]\n",
      "loss: 8.304111  [64064/116368]\n",
      "loss: 14.841495  [70464/116368]\n",
      "loss: 11.643661  [76864/116368]\n",
      "loss: 9.885407  [83264/116368]\n",
      "loss: 14.177910  [89664/116368]\n",
      "loss: 12.479425  [96064/116368]\n",
      "loss: 10.040418  [102464/116368]\n",
      "loss: 8.228547  [108864/116368]\n",
      "loss: 6.664699  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 14.163677  [   64/116368]\n",
      "loss: 9.128481  [ 6464/116368]\n",
      "loss: 12.424332  [12864/116368]\n",
      "loss: 13.368717  [19264/116368]\n",
      "loss: 10.755391  [25664/116368]\n",
      "loss: 11.650805  [32064/116368]\n",
      "loss: 8.357777  [38464/116368]\n",
      "loss: 11.647688  [44864/116368]\n",
      "loss: 10.003082  [51264/116368]\n",
      "loss: 10.814938  [57664/116368]\n",
      "loss: 12.570166  [64064/116368]\n",
      "loss: 10.034061  [70464/116368]\n",
      "loss: 14.147602  [76864/116368]\n",
      "loss: 9.926254  [83264/116368]\n",
      "loss: 12.605754  [89664/116368]\n",
      "loss: 10.804046  [96064/116368]\n",
      "loss: 11.666256  [102464/116368]\n",
      "loss: 12.558698  [108864/116368]\n",
      "loss: 9.974283  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 15.742613  [   64/116368]\n",
      "loss: 14.968748  [ 6464/116368]\n",
      "loss: 10.747963  [12864/116368]\n",
      "loss: 9.210409  [19264/116368]\n",
      "loss: 12.438635  [25664/116368]\n",
      "loss: 9.140371  [32064/116368]\n",
      "loss: 15.024854  [38464/116368]\n",
      "loss: 14.131845  [44864/116368]\n",
      "loss: 11.697203  [51264/116368]\n",
      "loss: 15.865883  [57664/116368]\n",
      "loss: 13.378386  [64064/116368]\n",
      "loss: 11.506820  [70464/116368]\n",
      "loss: 9.175836  [76864/116368]\n",
      "loss: 13.365629  [83264/116368]\n",
      "loss: 9.989852  [89664/116368]\n",
      "loss: 11.602096  [96064/116368]\n",
      "loss: 9.954277  [102464/116368]\n",
      "loss: 11.556448  [108864/116368]\n",
      "loss: 10.814473  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 11.796059 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 7.468616  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 67.187500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 68.750000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 92.187500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 68.750000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 87.500000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 90.625000  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 67.187500  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 90.625000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 89.062500  [12864/116368]\n",
      "loss: 89.062500  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 89.062500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 64.062500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 68.750000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 64.062500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 68.750000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 87.500000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 89.062500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 68.750000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 62.500000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 65.625000  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 65.625000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 67.187500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 70.312500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 0.005\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 67.187500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 89.062500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 92.187500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 64.062500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 93.750000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 89.062500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 67.187500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 93.750000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 87.500000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 87.500000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 89.062500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 87.500000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 89.062500  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 89.062500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 89.062500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 93.750000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 89.062500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 92.187500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 67.187500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 67.187500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 68.750000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 90.625000  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 67.187500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 87.500000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 90.625000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 67.187500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 87.500000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 67.187500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 65.625000  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 90.625000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 90.625000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 70.312500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 89.062500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 70.312500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 65.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 89.062500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 64.062500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 92.187500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 0.0005\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 89.062500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 65.625000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 65.625000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 65.625000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 65.625000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 65.625000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 90.625000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 90.625000  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 67.187500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 59.375000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 89.062500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 62.500000  [102464/116368]\n",
      "loss: 89.062500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 60.937500  [38464/116368]\n",
      "loss: 62.500000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 59.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 65.625000  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 62.500000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 89.062500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 70.312500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 87.500000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 62.500000  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 67.187500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 67.187500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 64.062500  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 67.187500  [102464/116368]\n",
      "loss: 89.062500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 92.187500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 67.187500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 89.062500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 87.500000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 87.500000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 64.062500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 90.625000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 87.500000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 67.187500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 89.062500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 65.625000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 67.187500  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 87.500000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 92.187500  [108864/116368]\n",
      "loss: 62.500000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 89.062500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 60.937500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 87.500000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 5e-05\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 89.062500  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 89.062500  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 89.062500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 68.750000  [89664/116368]\n",
      "loss: 90.625000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 68.750000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 89.062500  [70464/116368]\n",
      "loss: 64.062500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 90.625000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 68.750000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 62.500000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 89.062500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 93.750000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 87.500000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 87.500000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 67.187500  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 68.750000  [70464/116368]\n",
      "loss: 68.750000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 87.500000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 65.625000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 65.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 67.187500  [38464/116368]\n",
      "loss: 87.500000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 65.625000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 68.750000  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 89.062500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 68.750000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 87.500000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 65.625000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 89.062500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 68.750000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: RMSprop, Learning Rate: 1e-05\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 60.937500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 65.625000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 65.625000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 89.062500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 64.062500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 90.625000  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 87.500000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 92.187500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 67.187500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 95.312500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 92.187500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 90.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 68.750000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 89.062500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 67.187500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 89.062500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 68.750000  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 70.312500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 87.500000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 64.062500  [83264/116368]\n",
      "loss: 87.500000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 67.187500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 87.500000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 65.625000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 68.750000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 68.750000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 64.062500  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 67.187500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 87.500000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 89.062500  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 68.750000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 84.375000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 90.625000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 89.062500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 68.750000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 89.062500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 65.625000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 90.625000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 67.187500  [32064/116368]\n",
      "loss: 89.062500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 67.187500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 67.187500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 65.625000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 65.625000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 89.062500  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 68.750000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 87.500000  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 87.500000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 67.187500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 65.625000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 87.500000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 90.625000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 65.625000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 92.187500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 59.375000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 93.750000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 0.005\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 64.062500  [12864/116368]\n",
      "loss: 68.750000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 90.625000  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 67.187500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 87.500000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 87.500000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 90.625000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 67.187500  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 68.750000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 68.750000  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 92.187500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 60.937500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 65.625000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 68.750000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 89.062500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 65.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 89.062500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 65.625000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 90.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 64.062500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 89.062500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 90.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 89.062500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 85.937500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 87.500000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 65.625000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 70.312500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 65.625000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 89.062500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 90.625000  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 67.187500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 68.750000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 87.500000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 65.625000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 87.500000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 89.062500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 70.312500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 0.0005\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 89.062500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 87.500000  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 67.187500  [76864/116368]\n",
      "loss: 67.187500  [83264/116368]\n",
      "loss: 65.625000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 68.750000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 89.062500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 71.875000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 65.625000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 64.062500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 68.750000  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 67.187500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 70.312500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 67.187500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 87.500000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 68.750000  [70464/116368]\n",
      "loss: 65.625000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 87.500000  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 92.187500  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 67.187500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 89.062500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 89.062500  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 62.500000  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 93.750000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 89.062500  [   64/116368]\n",
      "loss: 87.500000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 67.187500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 67.187500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 87.500000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 68.750000  [83264/116368]\n",
      "loss: 85.937500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 90.625000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 89.062500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 90.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 89.062500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 68.750000  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 87.500000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 79.687500  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 68.750000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 89.062500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 73.437500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 89.062500  [32064/116368]\n",
      "loss: 92.187500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 67.187500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 89.062500  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 65.625000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 85.937500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 87.500000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 71.875000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 89.062500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 76.562500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 67.187500  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 89.062500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 67.187500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 84.375000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 89.062500  [102464/116368]\n",
      "loss: 81.250000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 90.625000  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 67.187500  [44864/116368]\n",
      "loss: 65.625000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 70.312500  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 90.625000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 68.750000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 67.187500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 85.937500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 89.062500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 70.312500  [12864/116368]\n",
      "loss: 87.500000  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 65.625000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 64.062500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 87.500000  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 68.750000  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 67.187500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 5e-05\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 76.562500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 65.625000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 87.500000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 82.812500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 68.750000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 85.937500  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 87.500000  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 68.750000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 87.500000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 84.375000  [25664/116368]\n",
      "loss: 71.875000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 87.500000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 70.312500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 67.187500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 82.812500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 87.500000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 82.812500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 65.625000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 90.625000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 60.937500  [83264/116368]\n",
      "loss: 84.375000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 87.500000  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 87.500000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 87.500000  [   64/116368]\n",
      "loss: 67.187500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 65.625000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 68.750000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 67.187500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 87.500000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 85.937500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 84.375000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 84.375000  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 67.187500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 67.187500  [12864/116368]\n",
      "loss: 70.312500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 68.750000  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 89.062500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 68.750000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 84.375000  [44864/116368]\n",
      "loss: 76.562500  [51264/116368]\n",
      "loss: 89.062500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 67.187500  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 70.312500  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 70.312500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 78.125000  [ 6464/116368]\n",
      "loss: 78.125000  [12864/116368]\n",
      "loss: 71.875000  [19264/116368]\n",
      "loss: 85.937500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 70.312500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 65.625000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 65.625000  [38464/116368]\n",
      "loss: 68.750000  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 82.812500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 82.812500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 73.437500  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 75.000000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 78.125000  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 71.875000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 71.875000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 70.312500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 68.750000  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 68.750000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 70.312500  [96064/116368]\n",
      "loss: 71.875000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 76.562500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n",
      "Training with optimizer: Adam, Learning Rate: 1e-05\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 68.750000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 87.500000  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 78.125000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 67.187500  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 75.000000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 73.437500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 90.625000  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 79.687500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 79.687500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 67.187500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 85.937500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 85.937500  [64064/116368]\n",
      "loss: 78.125000  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 68.750000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 67.187500  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 70.312500  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 89.062500  [38464/116368]\n",
      "loss: 85.937500  [44864/116368]\n",
      "loss: 81.250000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 71.875000  [64064/116368]\n",
      "loss: 89.062500  [70464/116368]\n",
      "loss: 78.125000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 87.500000  [89664/116368]\n",
      "loss: 85.937500  [96064/116368]\n",
      "loss: 75.000000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 89.062500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 75.000000  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 81.250000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 85.937500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 73.437500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 71.875000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 68.750000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 81.250000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 76.562500  [102464/116368]\n",
      "loss: 76.562500  [108864/116368]\n",
      "loss: 70.312500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 64.062500  [ 6464/116368]\n",
      "loss: 89.062500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 71.875000  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 84.375000  [64064/116368]\n",
      "loss: 87.500000  [70464/116368]\n",
      "loss: 75.000000  [76864/116368]\n",
      "loss: 84.375000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 85.937500  [102464/116368]\n",
      "loss: 71.875000  [108864/116368]\n",
      "loss: 84.375000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 78.125000  [   64/116368]\n",
      "loss: 70.312500  [ 6464/116368]\n",
      "loss: 68.750000  [12864/116368]\n",
      "loss: 78.125000  [19264/116368]\n",
      "loss: 73.437500  [25664/116368]\n",
      "loss: 76.562500  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 82.812500  [44864/116368]\n",
      "loss: 87.500000  [51264/116368]\n",
      "loss: 73.437500  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 70.312500  [70464/116368]\n",
      "loss: 71.875000  [76864/116368]\n",
      "loss: 89.062500  [83264/116368]\n",
      "loss: 79.687500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 82.812500  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 73.437500  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 82.812500  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 73.437500  [51264/116368]\n",
      "loss: 70.312500  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 76.562500  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 67.187500  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 70.312500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 84.375000  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 76.562500  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 76.562500  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 87.500000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 73.437500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 79.687500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 79.687500  [12864/116368]\n",
      "loss: 75.000000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 67.187500  [38464/116368]\n",
      "loss: 81.250000  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 76.562500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 65.625000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 70.312500  [102464/116368]\n",
      "loss: 73.437500  [108864/116368]\n",
      "loss: 68.750000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 84.375000  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 81.250000  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 82.812500  [25664/116368]\n",
      "loss: 87.500000  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 79.687500  [44864/116368]\n",
      "loss: 82.812500  [51264/116368]\n",
      "loss: 85.937500  [57664/116368]\n",
      "loss: 79.687500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 75.000000  [83264/116368]\n",
      "loss: 78.125000  [89664/116368]\n",
      "loss: 84.375000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 71.875000  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 92.187500  [12864/116368]\n",
      "loss: 82.812500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 78.125000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 67.187500  [51264/116368]\n",
      "loss: 78.125000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 73.437500  [76864/116368]\n",
      "loss: 73.437500  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 75.000000  [96064/116368]\n",
      "loss: 84.375000  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 78.125000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 81.250000  [ 6464/116368]\n",
      "loss: 85.937500  [12864/116368]\n",
      "loss: 76.562500  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 70.312500  [32064/116368]\n",
      "loss: 79.687500  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 75.000000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 81.250000  [70464/116368]\n",
      "loss: 87.500000  [76864/116368]\n",
      "loss: 81.250000  [83264/116368]\n",
      "loss: 81.250000  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 78.125000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 76.562500  [   64/116368]\n",
      "loss: 76.562500  [ 6464/116368]\n",
      "loss: 82.812500  [12864/116368]\n",
      "loss: 79.687500  [19264/116368]\n",
      "loss: 75.000000  [25664/116368]\n",
      "loss: 81.250000  [32064/116368]\n",
      "loss: 71.875000  [38464/116368]\n",
      "loss: 76.562500  [44864/116368]\n",
      "loss: 70.312500  [51264/116368]\n",
      "loss: 82.812500  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 76.562500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 85.937500  [83264/116368]\n",
      "loss: 70.312500  [89664/116368]\n",
      "loss: 78.125000  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 79.687500  [108864/116368]\n",
      "loss: 75.000000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 81.250000  [   64/116368]\n",
      "loss: 71.875000  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 81.250000  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 78.125000  [38464/116368]\n",
      "loss: 75.000000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 65.625000  [57664/116368]\n",
      "loss: 75.000000  [64064/116368]\n",
      "loss: 73.437500  [70464/116368]\n",
      "loss: 82.812500  [76864/116368]\n",
      "loss: 96.875000  [83264/116368]\n",
      "loss: 71.875000  [89664/116368]\n",
      "loss: 81.250000  [96064/116368]\n",
      "loss: 81.250000  [102464/116368]\n",
      "loss: 75.000000  [108864/116368]\n",
      "loss: 85.937500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 73.437500  [ 6464/116368]\n",
      "loss: 84.375000  [12864/116368]\n",
      "loss: 68.750000  [19264/116368]\n",
      "loss: 87.500000  [25664/116368]\n",
      "loss: 73.437500  [32064/116368]\n",
      "loss: 75.000000  [38464/116368]\n",
      "loss: 73.437500  [44864/116368]\n",
      "loss: 78.125000  [51264/116368]\n",
      "loss: 71.875000  [57664/116368]\n",
      "loss: 81.250000  [64064/116368]\n",
      "loss: 79.687500  [70464/116368]\n",
      "loss: 68.750000  [76864/116368]\n",
      "loss: 79.687500  [83264/116368]\n",
      "loss: 73.437500  [89664/116368]\n",
      "loss: 68.750000  [96064/116368]\n",
      "loss: 78.125000  [102464/116368]\n",
      "loss: 68.750000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 75.000000  [   64/116368]\n",
      "loss: 79.687500  [ 6464/116368]\n",
      "loss: 76.562500  [12864/116368]\n",
      "loss: 84.375000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 82.812500  [32064/116368]\n",
      "loss: 76.562500  [38464/116368]\n",
      "loss: 70.312500  [44864/116368]\n",
      "loss: 75.000000  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 73.437500  [64064/116368]\n",
      "loss: 82.812500  [70464/116368]\n",
      "loss: 84.375000  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 82.812500  [89664/116368]\n",
      "loss: 71.875000  [96064/116368]\n",
      "loss: 82.812500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 81.250000  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 82.812500  [   64/116368]\n",
      "loss: 85.937500  [ 6464/116368]\n",
      "loss: 73.437500  [12864/116368]\n",
      "loss: 81.250000  [19264/116368]\n",
      "loss: 79.687500  [25664/116368]\n",
      "loss: 75.000000  [32064/116368]\n",
      "loss: 84.375000  [38464/116368]\n",
      "loss: 71.875000  [44864/116368]\n",
      "loss: 79.687500  [51264/116368]\n",
      "loss: 81.250000  [57664/116368]\n",
      "loss: 78.125000  [64064/116368]\n",
      "loss: 85.937500  [70464/116368]\n",
      "loss: 79.687500  [76864/116368]\n",
      "loss: 78.125000  [83264/116368]\n",
      "loss: 75.000000  [89664/116368]\n",
      "loss: 76.562500  [96064/116368]\n",
      "loss: 79.687500  [102464/116368]\n",
      "loss: 84.375000  [108864/116368]\n",
      "loss: 79.687500  [115264/116368]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 77.823565 \n",
      "\n",
      "Test set Accuracy : 49.79%\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through optimizers and learning rates\n",
    "for optimizer_name, optimizer_class in optimizers.items():\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Training with optimizer: {optimizer_name}, Learning Rate: {lr}\")\n",
    "\n",
    "        # Define optimizer with current learning rate\n",
    "        optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epoch_num):\n",
    "            print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "            test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        for data, target in test_dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.data.max(1)[1]\n",
    "            correct += prediction.eq(target.data).sum()\n",
    "\n",
    "        accuracy = correct / len(test_dataloader.dataset)\n",
    "        print(f'Test set Accuracy : {accuracy:.2f}%')\n",
    "\n",
    "        # Append results to the list as tuple\n",
    "        results.append((optimizer_name, lr, accuracy.item()))\n",
    "\n",
    "# Convert the list of results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Optimizer', 'Learning Rate', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c1f2450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T05:20:43.183931Z",
     "iopub.status.busy": "2024-04-02T05:20:43.183278Z",
     "iopub.status.idle": "2024-04-02T05:20:43.196911Z",
     "shell.execute_reply": "2024-04-02T05:20:43.195787Z"
    },
    "papermill": {
     "duration": 0.311758,
     "end_time": "2024-04-02T05:20:43.199113",
     "exception": false,
     "start_time": "2024-04-02T05:20:42.887355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Optimizer      21 non-null     object \n",
      " 1   Learning Rate  21 non-null     float64\n",
      " 2   Accuracy       21 non-null     float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 632.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "results_df.to_csv(\"Results.csv\", index=False)\n",
    "results_df.info()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6012,
     "sourceId": 1733506,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1501.871121,
   "end_time": "2024-04-02T05:20:44.922550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-02T04:55:43.051429",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
